{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMWTcmgBk9QoIZ1fXlraqyo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfsanehHabibi/reddit-conversation-quality/blob/main/evidence.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anytree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl6FgX0hVQPg",
        "outputId": "19f59632-ad16-4a3f-c603-c03d0f89af0b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anytree\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUvhojH9U64n",
        "outputId": "1f48b91b-a580-467e-d078-63bf476289d6"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/University/RedditData/\""
      ],
      "metadata": {
        "id": "3kJGyiBjU9ax"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(f\"{base_path}conversations_with_reasoning_media_removed.pkl\", 'rb') as file:\n",
        "    conversations = pickle.load(file)\n",
        "\n",
        "print(\"Len loaded data:\", len(conversations))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LkqW8RFHUxDA",
        "outputId": "291e54dd-f21d-454e-e56f-a214ed2a701a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len loaded data: 18184\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_characters_from_end(input_string):\n",
        "    characters_to_remove = [')', '[', ')]', ').', '/', '/),']\n",
        "\n",
        "    # Use rstrip to remove the specified characters from the end of the string\n",
        "    for char in characters_to_remove:\n",
        "        input_string = input_string.rstrip(char)\n",
        "\n",
        "    return input_string"
      ],
      "metadata": {
        "id": "yriV6sr2wchg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "2c9o3f_2RVXw"
      },
      "outputs": [],
      "source": [
        "from urllib.parse import urlparse\n",
        "import re\n",
        "\n",
        "def find_urls_and_domains(text):\n",
        "    # Define a regex pattern to match URLs\n",
        "    url_pattern = re.compile(r'http[s]?://(?:[a-zA-Z]|[0-9]|[$-_@.&+]|[!*\\\\(\\\\),]|(?:%[0-9a-fA-F][0-9a-fA-F]))+')\n",
        "\n",
        "    # Find all matches in the text\n",
        "    urls = re.findall(url_pattern, text)\n",
        "\n",
        "    # Extract domains from URLs using urlparse with error handling\n",
        "    domains = []\n",
        "    for url in urls:\n",
        "        try:\n",
        "            domain = urlparse(url).hostname\n",
        "            domains.append((url, domain))\n",
        "        except ValueError as e:\n",
        "            result = url.split('](')\n",
        "            for part in result:\n",
        "                cleaned = remove_characters_from_end(part)\n",
        "                domain = urlparse(cleaned).hostname\n",
        "                domains.append((cleaned, domain))\n",
        "\n",
        "    return domains"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "domains = set()\n",
        "for key in conversations:\n",
        "  for comment in conversations[key]['comments']:\n",
        "    urls_and_domains = find_urls_and_domains(comment['body'])\n",
        "    comment['site_ref_count'] = len(urls_and_domains)\n",
        "    #for url, domain in urls_and_domains:\n",
        "    #       if domain and domain not in domains:\n",
        "    #           domains.add(domain)"
      ],
      "metadata": {
        "id": "SSqRHty_VY6l"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def write_conversations_with_site():\n",
        "  with open(f\"{base_path}conversations_with_sites.pkl\", 'wb') as file:\n",
        "    pickle.dump(conversations, file)\n",
        "  print(\"Variables written to the file.\")"
      ],
      "metadata": {
        "id": "Pwv042sl0lRd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "write_conversations_with_site()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G-5zHE9U2LKJ",
        "outputId": "99ed2934-356d-4f05-eef0-fcc1de00dc59"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables written to the file.\n"
          ]
        }
      ]
    }
  ]
}