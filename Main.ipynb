{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfsanehHabibi/reddit-conversation-quality/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nwsrw4kRxSO",
        "outputId": "2530217a-b19b-46a1-d5aa-023751504ae0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anytree\n",
            "  Downloading anytree-2.12.0-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.12.0\n"
          ]
        }
      ],
      "source": [
        "!pip install anytree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langdetect"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpq42XsomqOz",
        "outputId": "9eabbaf3-1499-4e18-9d09-9b2460310948"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.9/981.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m747.5/981.5 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=d5372a2b9eb1608ca741e54f806bbffc4a83acc8c08a8b55afbaf38db0db8fb5\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5J5hYGGO0I0"
      },
      "outputs": [],
      "source": [
        "#!pip3 install convokit\n",
        "#!python3 -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2nKEu6z62yR",
        "outputId": "ebc86567-820d-47f6-df37-e873dd7bae18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Preprocessing"
      ],
      "metadata": {
        "id": "L_70YRYLYNso"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g3cAemLLTz6h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from anytree import Node, RenderTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WF_hZIxO64-f"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/University/RedditData/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_files_list(file_list_path):\n",
        "    files_name = []\n",
        "    with open(file_list_path, 'r') as file_list:\n",
        "        for line in file_list:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                file_path, _ = line.split(',')\n",
        "                files_name.append(file_path)\n",
        "    return files_name"
      ],
      "metadata": {
        "id": "ZHFK04u4W1_r"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_files_name = extract_files_list(f\"{base_path}timestamps_seed2_num20_period10_date2022-10-1.txt_comments_progress.txt\")"
      ],
      "metadata": {
        "id": "wxmCIBekXfCX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_submission_file_path(file_name):\n",
        "    return f\"{base_path}submissions_{file_name}.json\""
      ],
      "metadata": {
        "id": "tZTRmfusY7K4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_comment_file_path(file_name):\n",
        "    return f\"{base_path}comments_{file_name}.json\""
      ],
      "metadata": {
        "id": "ybXnmbWIgl-D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subreddits = set()"
      ],
      "metadata": {
        "id": "36MQkOALazZV"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_submissions_text_with_filter(data_files_name):\n",
        "    submissions_dic = {}\n",
        "    over_18_count = 0\n",
        "    for file_name in data_files_name:\n",
        "        file_path = make_submission_file_path(file_name)\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines_sub = file.readlines()\n",
        "        for l in lines_sub:\n",
        "            obj = json.loads(l)\n",
        "            if obj['over_18'] == False:\n",
        "                submissions_dic[obj['id']]  = obj['title'] + obj['selftext']\n",
        "                subreddits.add(obj['subreddit'])\n",
        "            else:\n",
        "                over_18_count += 1\n",
        "    print(\"over 18 count \", over_18_count)\n",
        "    return submissions_dic"
      ],
      "metadata": {
        "id": "-EDIPZXzYJjf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subsmissions = extract_submissions_text_with_filter(data_files_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyrYu-8qbO9i",
        "outputId": "7027c874-52cd-4159-fd18-00a71788bf27"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "over 18 count  66876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(subsmissions)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzw-iWqGcN8J",
        "outputId": "6df419f0-06f1-4e48-c501-dfbd52dc9e64"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96333"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-gatXoaOEzjc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def count_comments_in_file(file_path):\n",
        "    count = 0\n",
        "    with open(file_path, 'r') as json_file:\n",
        "        lines = json_file.readlines()\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            count += len(data.get('comments', []))\n",
        "    return count\n",
        "\n",
        "def total_comments_in_files(file_list_path):\n",
        "    total_comments = 0\n",
        "    with open(file_list_path, 'r') as file_list:\n",
        "        for line in file_list:\n",
        "            print(line)\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                file_path, _ = line.split(',')\n",
        "                total_comments += count_comments_in_file(f\"{base_path}comments_{file_path}.json\")\n",
        "    return total_comments\n",
        "\n",
        "# Replace 'file_list.txt' with the path to your text file containing the list of file names\n",
        "#total_comments = total_comments_in_files(f\"{base_path}timestamps_seed2_num20_period10_date2022-10-1.txt_comments_progress.txt\")\n",
        "#print(f'Total number of comments in the files: {total_comments}')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_comments_with_filter(files_name, submmissions):\n",
        "    # Create a dictionary to store the comment nodes by their IDs\n",
        "    conversations_dic = {}\n",
        "    for file_name in data_files_name:\n",
        "        comment_file = make_comment_file_path(file_name)\n",
        "        with open(comment_file, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            comment_nodes = {}\n",
        "            json_obj = json.loads(line)\n",
        "            submission_id = json_obj['submission_id']\n",
        "            comments = json_obj['comments']\n",
        "            if len(comments) == 0:\n",
        "              continue\n",
        "            if submission_id not in subsmissions:\n",
        "                #submission has removed in preprocessing\n",
        "                continue\n",
        "            flat_comments_list = []\n",
        "            parent_child_pairs = []\n",
        "            # Create root node for the submission\n",
        "            submission_text = subsmissions[submission_id]\n",
        "            root = Node(submission_id, body = submission_text)\n",
        "            comment_nodes[submission_id] = root\n",
        "            conversation_text = submission_text\n",
        "            flat_comments_list.append({'id': submission_id, 'body': submission_text, 'author':None, 'reply_to':None, 'conversation_id':submission_id})\n",
        "            # Create child nodes for the comments\n",
        "            for comment in comments:\n",
        "                # Check if comment is from a bot and ignore it if it is\n",
        "                if \"I am a bot, and this action was performed automatically\" in comment['body']:\n",
        "                    continue\n",
        "\n",
        "                comment_id = comment['id']\n",
        "                author = comment.get('author_fullname', 'unknown')\n",
        "                parent_id = comment['parent_id'].split('_', 1)[-1]\n",
        "                body = comment['body']\n",
        "                comment_node = Node(comment_id, body=body)\n",
        "\n",
        "                if parent_id in comment_nodes:\n",
        "                    flat_comments_list.append({'id': comment_id, 'body': body, 'author':author, 'reply_to':parent_id, 'conversation_id':submission_id})\n",
        "                    parent_node = comment_nodes[parent_id]\n",
        "                    parent_child_pairs.append({\n",
        "                        'comment': parent_node.body,\n",
        "                        'reply': body,\n",
        "                        'comment_id': parent_node.name,\n",
        "                        'reply_id': comment_id,\n",
        "                        'global_id': parent_node.name + \"_\" + comment_id\n",
        "                    })\n",
        "                    comment_node.parent = parent_node\n",
        "                    conversation_text += \"/n\"+ body\n",
        "                    comment_nodes[comment_id] = comment_node\n",
        "            # Print the tree structure\n",
        "            # print(RenderTree(root))\n",
        "            conversations_dic[submission_id] = {\n",
        "                'tree': root,\n",
        "                'full_text': conversation_text,\n",
        "                'pairs': parent_child_pairs,\n",
        "                'comments': flat_comments_list\n",
        "            }\n",
        "            #for parent in root.children:\n",
        "            #  for child in parent.children:\n",
        "            #       parent_child_pairs.append((parent.body, child.body))\n",
        "\n",
        "            # Print the parent-child pairs\n",
        "            #for pair in parent_child_pairs:\n",
        "            #   print(f\"Parent: {pair[0]}, Child: {pair[1]}\")\n",
        "\n",
        "            # Print the tree structure\n",
        "            #for pre, fill, node in RenderTree(root):\n",
        "            #   print(f\"{pre}{node.name}\")\n",
        "\n",
        "        #print(RenderTree(conversations_tree[2555]))\n",
        "    return conversations_dic"
      ],
      "metadata": {
        "id": "5v3l38OFerIb"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conversations_dic = load_comments_with_filter(data_files_name, subsmissions)"
      ],
      "metadata": {
        "id": "DKtZ62JIixvx"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(conversations_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffWeiRW-j-Ij",
        "outputId": "6aa389f1-3b86-4cef-baad-59e751eb91a7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39784"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_empty_conversations(conversations_dic):\n",
        "  non_empty_conversations = {}\n",
        "  for id in conversations_dic:\n",
        "    new_pairs = []\n",
        "    pairs = conversations_dic[id]['pairs']\n",
        "    for pair in pairs:\n",
        "      if not(pair['comment'] == '[deleted]' or pair['reply'] == '[deleted]' or pair['comment'].endswith('[removed]')):\n",
        "        new_pairs.append(pair)\n",
        "    if len(new_pairs) > 0:\n",
        "      conversations_dic[id]['pairs'] = new_pairs\n",
        "      non_empty_conversations[id] = conversations_dic[id]\n",
        "  return non_empty_conversations\n"
      ],
      "metadata": {
        "id": "HmgKU0v5yaGw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "non_empty_conversations = filter_empty_conversations(conversations_dic)"
      ],
      "metadata": {
        "id": "ZLG3P45O53NQ"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(conversations_dic)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKb3hWFm-IW6",
        "outputId": "ec00f03b-3cd7-4f9b-a30b-e6a195cd4dc9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39784"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(non_empty_conversations)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8KEfKfH-GQP",
        "outputId": "400401c2-df72-4203-f91e-c4f0e5a66cc0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35393"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langdetect import detect, LangDetectException\n",
        "\n",
        "def filter_non_english(conversations_dic):\n",
        "    english_conversations = {}\n",
        "    for id in conversations_dic:\n",
        "        try:\n",
        "            language = detect(conversations_dic[id]['full_text'])\n",
        "            if language == 'en':\n",
        "                english_conversations[id] = conversations_dic[id]\n",
        "        except LangDetectException as e:\n",
        "            # Handle the exception and print the problematic input\n",
        "            # print(f\"Language detection error for comment: {conversations_dic[id]['full_text']}\")\n",
        "            continue\n",
        "    return english_conversations"
      ],
      "metadata": {
        "id": "w4c4sbU4nK5_"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "english_conversations = filter_non_english(non_empty_conversations)"
      ],
      "metadata": {
        "id": "nD_P8W5qWsHb"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(english_conversations)"
      ],
      "metadata": {
        "id": "yk6xYJSqWz0y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe950e2d-b646-4a3b-b217-2c517d2ad5eb"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33580"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_pair = random.choice(list(english_conversations.items()))\n",
        "random_pair[1]['pairs']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGRc-uliMFrf",
        "outputId": "3ca6b48f-890e-4016-885b-7081bacf6969"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'comment': '[Misc] Skin purgingHow can you tell the difference between skin purging and the product just not working for you?\\n\\nAlso any recommendations on products that helps skin that gets reddish throughout the day? \\nThanks for the feedback!!',\n",
              "  'reply': 'Do you use niaciadmide at night? It can cause flushing and can be sun reactive. I always put mine on at night.',\n",
              "  'comment_id': 'xxhg0m',\n",
              "  'reply_id': 'ircuoec',\n",
              "  'global_id': 'xxhg0m_ircuoec'},\n",
              " {'comment': '[Misc] Skin purgingHow can you tell the difference between skin purging and the product just not working for you?\\n\\nAlso any recommendations on products that helps skin that gets reddish throughout the day? \\nThanks for the feedback!!',\n",
              "  'reply': 'If the skin purging spots seem to go away quicker than normal acne, its purging cause of the high cell turnover. If not, it is a breakout.',\n",
              "  'comment_id': 'xxhg0m',\n",
              "  'reply_id': 'irc3gz4',\n",
              "  'global_id': 'xxhg0m_irc3gz4'},\n",
              " {'comment': '[Misc] Skin purgingHow can you tell the difference between skin purging and the product just not working for you?\\n\\nAlso any recommendations on products that helps skin that gets reddish throughout the day? \\nThanks for the feedback!!',\n",
              "  'reply': 'Try to use fragrance free products, I also use caffine serum on my face 2× a day,  shower in cooler water, eat more fruits and veggies and a good moisturizers. \\n\\n Figure out what your triggers are for redness it could be diet, caffine consumption, wind, humidity,sun. Just to name a few. \\n\\nI never wore sunscreen daily (only when I went out side for extended periods of time) and since I started wearing a daily SPF my everyday redness has gone down.',\n",
              "  'comment_id': 'xxhg0m',\n",
              "  'reply_id': 'ircughx',\n",
              "  'global_id': 'xxhg0m_ircughx'},\n",
              " {'comment': '[Misc] Skin purgingHow can you tell the difference between skin purging and the product just not working for you?\\n\\nAlso any recommendations on products that helps skin that gets reddish throughout the day? \\nThanks for the feedback!!',\n",
              "  'reply': \"What's your routine like? I have sensitive skin and I'm reddish if its windy or its sunny. Are you using a daily  sunscreen?\",\n",
              "  'comment_id': 'xxhg0m',\n",
              "  'reply_id': 'ircgc9m',\n",
              "  'global_id': 'xxhg0m_ircgc9m'},\n",
              " {'comment': 'Do you use niaciadmide at night? It can cause flushing and can be sun reactive. I always put mine on at night.',\n",
              "  'reply': \"I use it am and pm. I didnt know that! Maybe I'll just apply it at night\",\n",
              "  'comment_id': 'ircuoec',\n",
              "  'reply_id': 'ircwi6b',\n",
              "  'global_id': 'ircuoec_ircwi6b'},\n",
              " {'comment': \"What's your routine like? I have sensitive skin and I'm reddish if its windy or its sunny. Are you using a daily  sunscreen?\",\n",
              "  'reply': \"I use jelly cleanser from hero cosmetics, niacinamide serum from good molecules, clarifying prebiotic moisturizer from hero cosmetics and for sunscreen, force shield superlight sunscreen from hero cosmetics \\n\\nWhat products do you use to keep the redness at bay? When I'm hot, my face will get red etc\",\n",
              "  'comment_id': 'ircgc9m',\n",
              "  'reply_id': 'ircok69',\n",
              "  'global_id': 'ircgc9m_ircok69'}]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "def contains_question(text):\n",
        "    # Check if the text contains a question mark\n",
        "    if '?' in text:\n",
        "        return True\n",
        "\n",
        "    # Check if the text contains certain question words\n",
        "    question_words = ['what', 'how', 'when', 'where', 'who', 'why']\n",
        "    for word in question_words:\n",
        "        if re.search(r'\\b{}\\b'.format(word), text, re.IGNORECASE):\n",
        "            return True\n",
        "\n",
        "    # Check if the text contains the word \"please\"\n",
        "    if re.search(r'\\bplease\\b', text, re.IGNORECASE):\n",
        "        return True\n",
        "\n",
        "    # If none of the above conditions are met, return False\n",
        "    return False\n",
        "\n",
        "# Example usage\n",
        "text = \"What is the capital of France? I love Paris. How do you make a cake? The recipe is easy to follow. Can you please pass the salt?\"\n",
        "if contains_question(text):\n",
        "    print(\"The text contains a question.\")\n",
        "else:\n",
        "    print(\"The text does not contain a question.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwV-WRFiQHxf",
        "outputId": "54f6c763-0a4d-4a91-e7ef-d1187aa6aef7"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text contains a question.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz-OYtq6-iuo",
        "outputId": "4cf48f7b-27be-4fb9-c680-2f3eb6198c8e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iqmyeuo: Hey, we launched a new music-scanning feature at Soundslice just a few days ago ([see here](https://www.soundslice.com/blog/226/pdf-and-photo-scanning-beta/)). It uses artificial intelligence to convert PDFs/images into editable sheet music.\n",
            "\n",
            "I'm happy to run a PDF through it for you if you'd like — just send me a DM!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Node('/xsyewi', body=\"Has Anyone Tried Scanscore ?I've been trying to find a pdf scanner app or program that can scan sheet music and turn it into a **musicxml** format. I came across Scanscore, but I don't if it's any good. anyone in this sub try it? would you recommend it?\")]"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# Define the sample size (e.g., 3 for a sample of 3 elements)\n",
        "sample_size = 1\n",
        "\n",
        "# Use random.sample to get a random sample of the specified size\n",
        "random_sample = random.sample(conversations_tree, sample_size)\n",
        "from anytree import PreOrderIter\n",
        "\n",
        "# Assuming 'root' is the root node of the conversation tree\n",
        "for node in PreOrderIter(random_sample[0]):\n",
        "    if node.parent is not None:\n",
        "        print(f\"{node.name}: {node.body}\")\n",
        "\n",
        "random_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzvR0YnpSdWM",
        "outputId": "e2739377-27b5-47ea-dd13-c595d30df98f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: kili in /usr/local/lib/python3.10/dist-packages (2.147.4)\n",
            "Requirement already satisfied: pandas<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (1.5.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (2.31.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from kili) (0.9.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (8.2.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (4.66.1)\n",
            "Requirement already satisfied: typeguard<5,>=4 in /usr/local/lib/python3.10/dist-packages (from kili) (4.1.5)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from kili) (4.8.0)\n",
            "Requirement already satisfied: pyparsing<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (3.1.1)\n",
            "Requirement already satisfied: websocket-client<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (1.6.4)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from kili) (6.0.1)\n",
            "Requirement already satisfied: Pillow<10.1.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (9.4.0)\n",
            "Requirement already satisfied: cuid<0.5,>=0.4 in /usr/local/lib/python3.10/dist-packages (from kili) (0.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from kili) (2.0.7)\n",
            "Requirement already satisfied: ffmpeg-python<0.3.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from kili) (0.2.0)\n",
            "Requirement already satisfied: gql[requests,websockets]<4.0.0,>=3.5.0b5 in /usr/local/lib/python3.10/dist-packages (from kili) (3.5.0b6)\n",
            "Requirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (3.12.4)\n",
            "Requirement already satisfied: pyrate-limiter<3,>=2 in /usr/local/lib/python3.10/dist-packages (from kili) (2.10.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python<0.3.0,>=0.2.0->kili) (0.18.3)\n",
            "Requirement already satisfied: graphql-core<3.4,>=3.3.0a3 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (3.3.0a3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (1.9.2)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (2.2.1)\n",
            "Requirement already satisfied: websockets<12,>=10 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (11.0.3)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (1.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (3.3.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (2023.7.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3.0.0,>=1.0.0->kili) (1.16.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (6.0.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install  kili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVwzZgyHdRg8",
        "outputId": "f3e5378a-6ebd-4725-8296-8489faa0b104"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Project ID:  clo71jb7a1nxb079tdn1zh7hn\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from kili.client import Kili\n",
        "kili = Kili(api_key='6acd489f-9746-4ac4-9650-54e2d9c9faba')\n",
        "interface = {\n",
        "    \"jobs\": {\n",
        "        \"JOB_0\": {\n",
        "            \"mlTask\": \"CLASSIFICATION\",\n",
        "            \"required\": 1,\n",
        "            \"isChild\": False,\n",
        "            \"content\": {\n",
        "                \"categories\": {\"Related\": {\"name\": \"is related\"}, \"UnRelated\": {\"name\": \"is not related\"}},\n",
        "                \"input\": \"radio\",\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "project = kili.create_project(\n",
        "    title=\"Testing ...\",\n",
        "    description=\"Project Description\",\n",
        "    input_type=\"TEXT\",\n",
        "    json_interface=interface,\n",
        ")\n",
        "project_id = project['id']\n",
        "print(\"Project ID: \", project_id)\n",
        "assets = kili.append_many_to_dataset(\n",
        "    project_id=project_id,\n",
        "    content_array = [(d['comment'] + d['reply']) for d in parent_child_pairs[:5]],\n",
        "    external_id_array = [d['global_id'] for d in parent_child_pairs[:5]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udPeZAdjp0hd",
        "outputId": "2db17f27-bb07-4f36-95f7-00e31d48393f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parent: iqmum2s, Child: iqmunnz\n",
            "Parent: iqmum2s, Child: iqmuns8\n",
            "Parent: iqon7tc, Child: iqrmqmy\n",
            "xsy76f\n",
            "├── iqmum2s\n",
            "│   ├── iqmunnz\n",
            "│   └── iqmuns8\n",
            "├── iqob6q0\n",
            "└── iqon7tc\n",
            "    └── iqrmqmy\n",
            "        └── iqsvfoq\n"
          ]
        }
      ],
      "source": [
        "from anytree import Node, RenderTree\n",
        "\n",
        "# Create a list to store parent-child pairs\n",
        "parent_child_pairs = []\n",
        "\n",
        "# Access child nodes from the parent node and add the pairs to the list\n",
        "for parent in root.children:\n",
        "    for child in parent.children:\n",
        "        parent_child_pairs.append((parent.name, child.name))\n",
        "\n",
        "# Print the parent-child pairs\n",
        "for pair in parent_child_pairs:\n",
        "    print(f\"Parent: {pair[0]}, Child: {pair[1]}\")\n",
        "\n",
        "# Print the tree structure\n",
        "for pre, fill, node in RenderTree(root):\n",
        "    print(f\"{pre}{node.name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4brlEl0nruv",
        "outputId": "3d358491-66e0-46dd-aa34-c916afe67658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been prepared for Kili labeling.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "for comment in flat_comments_list:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJJSGUQj3m46"
      },
      "outputs": [],
      "source": [
        "formatted_data = []\n",
        "for comment in flat_comments_list:\n",
        "    formatted_comment = {\n",
        "        \"row_data\": comment['body'],\n",
        "        \"global_key\": comment['id'],\n",
        "        \"media_type\": \"TEXT\",\n",
        "        \"metadata_fields\": [],\n",
        "        \"attachments\": []\n",
        "    }\n",
        "    formatted_data.append(formatted_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTQdXVen1Esj",
        "outputId": "b6f9e540-0d9b-491c-c361-9fa3cf5c0db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been written to formatted_comments.json\n"
          ]
        }
      ],
      "source": [
        "with open(base_path +\"flat_comments_list.json\", \"w\") as json_file:\n",
        "    json.dump(flat_comments_list, json_file, indent=2)\n",
        "\n",
        "print(\"Data has been written to formatted_comments.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62FjApSor6r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "evaEvX_QopHZ",
        "outputId": "3c2a8a3f-c192-40a4-8e41-d36401970bda"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3beb6b0771e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconversations_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: 0 is not in list"
          ]
        }
      ],
      "source": [
        "conversations_tree.index(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSeMoQFZQ5Ze"
      },
      "outputs": [],
      "source": [
        "def flatten_tree(node, flattened_tree):\n",
        "    flattened_tree.append(node)\n",
        "    for child in node.children:\n",
        "        flatten_tree(child, flattened_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWwi-EwdPwJe"
      },
      "outputs": [],
      "source": [
        "flattened_tree = []\n",
        "flatten_tree(root, flattened_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0WMaY9uoli3",
        "outputId": "a26dd0d8-6816-4e35-e071-81b5b7904cfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function __main__.flatten_tree(node, flattened_tree)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flatten_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbP4uSHiRw_k"
      },
      "outputs": [],
      "source": [
        "# there is node without body!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwRWOf09RWQr"
      },
      "outputs": [],
      "source": [
        "from convokit import Corpus, Utterance, Speaker\n",
        "# Create a Corpus object from the flattened tree.\n",
        "corpus = Corpus(utterances=[\n",
        "        Utterance(id=node['id'], text=node['body'], speaker=Speaker(id = node['author']), reply_to=node['reply_to'], conversation_id=node['conversation_id'])\n",
        "        for node in flat_comments_list\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "TEEuPkkmsWXD",
        "outputId": "c4d6035d-67b6-49bd-c138-e3abaa53e4bf"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-fe0bc8cfc776>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Corpus' object has no attribute 'fit'"
          ]
        }
      ],
      "source": [
        "corpus = corpus.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t26-KJvk3WN",
        "outputId": "0f8803fa-fb8e-4e86-8191-0a0a0d576961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2940\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "for convo in corpus.iter_conversations():\n",
        "    counter+=1\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b__m1fESn2QW",
        "outputId": "bcb5b6bd-2d9b-4f77-de14-cb0966adfd08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Speakers: 20381\n",
            "Number of Utterances: 37647\n",
            "Number of Conversations: 2940\n"
          ]
        }
      ],
      "source": [
        "corpus.print_summary_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGmGvNjMtr_1",
        "outputId": "07a02ab5-ba26-4d39-95b3-8b80de0e63f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/37647 utterances processed\n",
            "200/37647 utterances processed\n",
            "300/37647 utterances processed\n",
            "400/37647 utterances processed\n",
            "500/37647 utterances processed\n",
            "600/37647 utterances processed\n",
            "700/37647 utterances processed\n",
            "800/37647 utterances processed\n",
            "900/37647 utterances processed\n",
            "1000/37647 utterances processed\n",
            "1100/37647 utterances processed\n",
            "1200/37647 utterances processed\n",
            "1300/37647 utterances processed\n",
            "1400/37647 utterances processed\n",
            "1500/37647 utterances processed\n",
            "1600/37647 utterances processed\n",
            "1700/37647 utterances processed\n",
            "1800/37647 utterances processed\n",
            "1900/37647 utterances processed\n",
            "2000/37647 utterances processed\n",
            "2100/37647 utterances processed\n",
            "2200/37647 utterances processed\n",
            "2300/37647 utterances processed\n",
            "2400/37647 utterances processed\n",
            "2500/37647 utterances processed\n",
            "2600/37647 utterances processed\n",
            "2700/37647 utterances processed\n",
            "2800/37647 utterances processed\n",
            "2900/37647 utterances processed\n",
            "3000/37647 utterances processed\n",
            "3100/37647 utterances processed\n",
            "3200/37647 utterances processed\n",
            "3300/37647 utterances processed\n",
            "3400/37647 utterances processed\n",
            "3500/37647 utterances processed\n",
            "3600/37647 utterances processed\n",
            "3700/37647 utterances processed\n",
            "3800/37647 utterances processed\n",
            "3900/37647 utterances processed\n",
            "4000/37647 utterances processed\n",
            "4100/37647 utterances processed\n",
            "4200/37647 utterances processed\n",
            "4300/37647 utterances processed\n",
            "4400/37647 utterances processed\n",
            "4500/37647 utterances processed\n",
            "4600/37647 utterances processed\n",
            "4700/37647 utterances processed\n",
            "4800/37647 utterances processed\n",
            "4900/37647 utterances processed\n",
            "5000/37647 utterances processed\n",
            "5100/37647 utterances processed\n",
            "5200/37647 utterances processed\n",
            "5300/37647 utterances processed\n",
            "5400/37647 utterances processed\n",
            "5500/37647 utterances processed\n",
            "5600/37647 utterances processed\n",
            "5700/37647 utterances processed\n",
            "5800/37647 utterances processed\n",
            "5900/37647 utterances processed\n",
            "6000/37647 utterances processed\n",
            "6100/37647 utterances processed\n",
            "6200/37647 utterances processed\n",
            "6300/37647 utterances processed\n",
            "6400/37647 utterances processed\n",
            "6500/37647 utterances processed\n",
            "6600/37647 utterances processed\n",
            "6700/37647 utterances processed\n",
            "6800/37647 utterances processed\n",
            "6900/37647 utterances processed\n",
            "7000/37647 utterances processed\n",
            "7100/37647 utterances processed\n",
            "7200/37647 utterances processed\n",
            "7300/37647 utterances processed\n",
            "7400/37647 utterances processed\n",
            "7500/37647 utterances processed\n",
            "7600/37647 utterances processed\n",
            "7700/37647 utterances processed\n",
            "7800/37647 utterances processed\n",
            "7900/37647 utterances processed\n",
            "8000/37647 utterances processed\n",
            "8100/37647 utterances processed\n",
            "8200/37647 utterances processed\n",
            "8300/37647 utterances processed\n",
            "8400/37647 utterances processed\n",
            "8500/37647 utterances processed\n",
            "8600/37647 utterances processed\n",
            "8700/37647 utterances processed\n",
            "8800/37647 utterances processed\n",
            "8900/37647 utterances processed\n",
            "9000/37647 utterances processed\n",
            "9100/37647 utterances processed\n",
            "9200/37647 utterances processed\n",
            "9300/37647 utterances processed\n",
            "9400/37647 utterances processed\n",
            "9500/37647 utterances processed\n",
            "9600/37647 utterances processed\n",
            "9700/37647 utterances processed\n",
            "9800/37647 utterances processed\n",
            "9900/37647 utterances processed\n",
            "10000/37647 utterances processed\n",
            "10100/37647 utterances processed\n",
            "10200/37647 utterances processed\n",
            "10300/37647 utterances processed\n",
            "10400/37647 utterances processed\n",
            "10500/37647 utterances processed\n",
            "10600/37647 utterances processed\n",
            "10700/37647 utterances processed\n",
            "10800/37647 utterances processed\n",
            "10900/37647 utterances processed\n",
            "11000/37647 utterances processed\n",
            "11100/37647 utterances processed\n",
            "11200/37647 utterances processed\n",
            "11300/37647 utterances processed\n",
            "11400/37647 utterances processed\n",
            "11500/37647 utterances processed\n",
            "11600/37647 utterances processed\n",
            "11700/37647 utterances processed\n",
            "11800/37647 utterances processed\n",
            "11900/37647 utterances processed\n",
            "12000/37647 utterances processed\n",
            "12100/37647 utterances processed\n",
            "12200/37647 utterances processed\n",
            "12300/37647 utterances processed\n",
            "12400/37647 utterances processed\n",
            "12500/37647 utterances processed\n",
            "12600/37647 utterances processed\n",
            "12700/37647 utterances processed\n",
            "12800/37647 utterances processed\n",
            "12900/37647 utterances processed\n",
            "13000/37647 utterances processed\n",
            "13100/37647 utterances processed\n",
            "13200/37647 utterances processed\n",
            "13300/37647 utterances processed\n",
            "13400/37647 utterances processed\n",
            "13500/37647 utterances processed\n",
            "13600/37647 utterances processed\n",
            "13700/37647 utterances processed\n",
            "13800/37647 utterances processed\n",
            "13900/37647 utterances processed\n",
            "14000/37647 utterances processed\n",
            "14100/37647 utterances processed\n",
            "14200/37647 utterances processed\n",
            "14300/37647 utterances processed\n",
            "14400/37647 utterances processed\n",
            "14500/37647 utterances processed\n",
            "14600/37647 utterances processed\n",
            "14700/37647 utterances processed\n",
            "14800/37647 utterances processed\n",
            "14900/37647 utterances processed\n",
            "15000/37647 utterances processed\n",
            "15100/37647 utterances processed\n",
            "15200/37647 utterances processed\n",
            "15300/37647 utterances processed\n",
            "15400/37647 utterances processed\n",
            "15500/37647 utterances processed\n",
            "15600/37647 utterances processed\n",
            "15700/37647 utterances processed\n",
            "15800/37647 utterances processed\n",
            "15900/37647 utterances processed\n",
            "16000/37647 utterances processed\n",
            "16100/37647 utterances processed\n",
            "16200/37647 utterances processed\n",
            "16300/37647 utterances processed\n",
            "16400/37647 utterances processed\n",
            "16500/37647 utterances processed\n",
            "16600/37647 utterances processed\n",
            "16700/37647 utterances processed\n",
            "16800/37647 utterances processed\n",
            "16900/37647 utterances processed\n",
            "17000/37647 utterances processed\n",
            "17100/37647 utterances processed\n",
            "17200/37647 utterances processed\n",
            "17300/37647 utterances processed\n",
            "17400/37647 utterances processed\n",
            "17500/37647 utterances processed\n",
            "17600/37647 utterances processed\n",
            "17700/37647 utterances processed\n",
            "17800/37647 utterances processed\n",
            "17900/37647 utterances processed\n",
            "18000/37647 utterances processed\n",
            "18100/37647 utterances processed\n",
            "18200/37647 utterances processed\n",
            "18300/37647 utterances processed\n",
            "18400/37647 utterances processed\n",
            "18500/37647 utterances processed\n",
            "18600/37647 utterances processed\n",
            "18700/37647 utterances processed\n",
            "18800/37647 utterances processed\n",
            "18900/37647 utterances processed\n",
            "19000/37647 utterances processed\n",
            "19100/37647 utterances processed\n",
            "19200/37647 utterances processed\n",
            "19300/37647 utterances processed\n",
            "19400/37647 utterances processed\n",
            "19500/37647 utterances processed\n",
            "19600/37647 utterances processed\n",
            "19700/37647 utterances processed\n",
            "19800/37647 utterances processed\n",
            "19900/37647 utterances processed\n",
            "20000/37647 utterances processed\n",
            "20100/37647 utterances processed\n",
            "20200/37647 utterances processed\n",
            "20300/37647 utterances processed\n",
            "20400/37647 utterances processed\n",
            "20500/37647 utterances processed\n",
            "20600/37647 utterances processed\n",
            "20700/37647 utterances processed\n",
            "20800/37647 utterances processed\n",
            "20900/37647 utterances processed\n",
            "21000/37647 utterances processed\n",
            "21100/37647 utterances processed\n",
            "21200/37647 utterances processed\n",
            "21300/37647 utterances processed\n",
            "21400/37647 utterances processed\n",
            "21500/37647 utterances processed\n",
            "21600/37647 utterances processed\n",
            "21700/37647 utterances processed\n",
            "21800/37647 utterances processed\n",
            "21900/37647 utterances processed\n",
            "22000/37647 utterances processed\n",
            "22100/37647 utterances processed\n",
            "22200/37647 utterances processed\n",
            "22300/37647 utterances processed\n",
            "22400/37647 utterances processed\n",
            "22500/37647 utterances processed\n",
            "22600/37647 utterances processed\n",
            "22700/37647 utterances processed\n",
            "22800/37647 utterances processed\n",
            "22900/37647 utterances processed\n",
            "23000/37647 utterances processed\n",
            "23100/37647 utterances processed\n",
            "23200/37647 utterances processed\n",
            "23300/37647 utterances processed\n",
            "23400/37647 utterances processed\n",
            "23500/37647 utterances processed\n",
            "23600/37647 utterances processed\n",
            "23700/37647 utterances processed\n",
            "23800/37647 utterances processed\n",
            "23900/37647 utterances processed\n",
            "24000/37647 utterances processed\n",
            "24100/37647 utterances processed\n",
            "24200/37647 utterances processed\n",
            "24300/37647 utterances processed\n",
            "24400/37647 utterances processed\n",
            "24500/37647 utterances processed\n",
            "24600/37647 utterances processed\n",
            "24700/37647 utterances processed\n",
            "24800/37647 utterances processed\n",
            "24900/37647 utterances processed\n",
            "25000/37647 utterances processed\n",
            "25100/37647 utterances processed\n",
            "25200/37647 utterances processed\n",
            "25300/37647 utterances processed\n",
            "25400/37647 utterances processed\n",
            "25500/37647 utterances processed\n",
            "25600/37647 utterances processed\n",
            "25700/37647 utterances processed\n",
            "25800/37647 utterances processed\n",
            "25900/37647 utterances processed\n",
            "26000/37647 utterances processed\n",
            "26100/37647 utterances processed\n",
            "26200/37647 utterances processed\n",
            "26300/37647 utterances processed\n",
            "26400/37647 utterances processed\n",
            "26500/37647 utterances processed\n",
            "26600/37647 utterances processed\n",
            "26700/37647 utterances processed\n",
            "26800/37647 utterances processed\n",
            "26900/37647 utterances processed\n",
            "27000/37647 utterances processed\n",
            "27100/37647 utterances processed\n",
            "27200/37647 utterances processed\n",
            "27300/37647 utterances processed\n",
            "27400/37647 utterances processed\n",
            "27500/37647 utterances processed\n",
            "27600/37647 utterances processed\n",
            "27700/37647 utterances processed\n",
            "27800/37647 utterances processed\n",
            "27900/37647 utterances processed\n",
            "28000/37647 utterances processed\n",
            "28100/37647 utterances processed\n",
            "28200/37647 utterances processed\n",
            "28300/37647 utterances processed\n",
            "28400/37647 utterances processed\n",
            "28500/37647 utterances processed\n",
            "28600/37647 utterances processed\n",
            "28700/37647 utterances processed\n",
            "28800/37647 utterances processed\n",
            "28900/37647 utterances processed\n",
            "29000/37647 utterances processed\n",
            "29100/37647 utterances processed\n",
            "29200/37647 utterances processed\n",
            "29300/37647 utterances processed\n",
            "29400/37647 utterances processed\n",
            "29500/37647 utterances processed\n",
            "29600/37647 utterances processed\n",
            "29700/37647 utterances processed\n",
            "29800/37647 utterances processed\n",
            "29900/37647 utterances processed\n",
            "30000/37647 utterances processed\n",
            "30100/37647 utterances processed\n",
            "30200/37647 utterances processed\n",
            "30300/37647 utterances processed\n",
            "30400/37647 utterances processed\n",
            "30500/37647 utterances processed\n",
            "30600/37647 utterances processed\n",
            "30700/37647 utterances processed\n",
            "30800/37647 utterances processed\n",
            "30900/37647 utterances processed\n",
            "31000/37647 utterances processed\n",
            "31100/37647 utterances processed\n",
            "31200/37647 utterances processed\n",
            "31300/37647 utterances processed\n",
            "31400/37647 utterances processed\n",
            "31500/37647 utterances processed\n",
            "31600/37647 utterances processed\n",
            "31700/37647 utterances processed\n",
            "31800/37647 utterances processed\n",
            "31900/37647 utterances processed\n",
            "32000/37647 utterances processed\n",
            "32100/37647 utterances processed\n",
            "32200/37647 utterances processed\n",
            "32300/37647 utterances processed\n",
            "32400/37647 utterances processed\n",
            "32500/37647 utterances processed\n",
            "32600/37647 utterances processed\n",
            "32700/37647 utterances processed\n",
            "32800/37647 utterances processed\n",
            "32900/37647 utterances processed\n",
            "33000/37647 utterances processed\n",
            "33100/37647 utterances processed\n",
            "33200/37647 utterances processed\n",
            "33300/37647 utterances processed\n",
            "33400/37647 utterances processed\n",
            "33500/37647 utterances processed\n",
            "33600/37647 utterances processed\n",
            "33700/37647 utterances processed\n",
            "33800/37647 utterances processed\n",
            "33900/37647 utterances processed\n",
            "34000/37647 utterances processed\n",
            "34100/37647 utterances processed\n",
            "34200/37647 utterances processed\n",
            "34300/37647 utterances processed\n",
            "34400/37647 utterances processed\n",
            "34500/37647 utterances processed\n",
            "34600/37647 utterances processed\n",
            "34700/37647 utterances processed\n",
            "34800/37647 utterances processed\n",
            "34900/37647 utterances processed\n",
            "35000/37647 utterances processed\n",
            "35100/37647 utterances processed\n",
            "35200/37647 utterances processed\n",
            "35300/37647 utterances processed\n",
            "35400/37647 utterances processed\n",
            "35500/37647 utterances processed\n",
            "35600/37647 utterances processed\n",
            "35700/37647 utterances processed\n",
            "35800/37647 utterances processed\n",
            "35900/37647 utterances processed\n",
            "36000/37647 utterances processed\n",
            "36100/37647 utterances processed\n",
            "36200/37647 utterances processed\n",
            "36300/37647 utterances processed\n",
            "36400/37647 utterances processed\n",
            "36500/37647 utterances processed\n",
            "36600/37647 utterances processed\n",
            "36700/37647 utterances processed\n",
            "36800/37647 utterances processed\n",
            "36900/37647 utterances processed\n",
            "37000/37647 utterances processed\n",
            "37100/37647 utterances processed\n",
            "37200/37647 utterances processed\n",
            "37300/37647 utterances processed\n",
            "37400/37647 utterances processed\n",
            "37500/37647 utterances processed\n",
            "37600/37647 utterances processed\n",
            "37647/37647 utterances processed\n"
          ]
        }
      ],
      "source": [
        "from convokit.text_processing import TextParser\n",
        "parser = TextParser(verbosity=100)\n",
        "corpus = parser.transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jc_3ZnHmUrr",
        "outputId": "c1779f12-0661-4a59-9110-83ce33ff6048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000/37647 utterances processed\n",
            "2000/37647 utterances processed\n",
            "3000/37647 utterances processed\n",
            "4000/37647 utterances processed\n",
            "5000/37647 utterances processed\n",
            "6000/37647 utterances processed\n",
            "7000/37647 utterances processed\n",
            "8000/37647 utterances processed\n",
            "9000/37647 utterances processed\n",
            "10000/37647 utterances processed\n",
            "11000/37647 utterances processed\n",
            "12000/37647 utterances processed\n",
            "13000/37647 utterances processed\n",
            "14000/37647 utterances processed\n",
            "15000/37647 utterances processed\n",
            "16000/37647 utterances processed\n",
            "17000/37647 utterances processed\n",
            "18000/37647 utterances processed\n",
            "19000/37647 utterances processed\n",
            "20000/37647 utterances processed\n",
            "21000/37647 utterances processed\n",
            "22000/37647 utterances processed\n",
            "23000/37647 utterances processed\n",
            "24000/37647 utterances processed\n",
            "25000/37647 utterances processed\n",
            "26000/37647 utterances processed\n",
            "27000/37647 utterances processed\n",
            "28000/37647 utterances processed\n",
            "29000/37647 utterances processed\n",
            "30000/37647 utterances processed\n",
            "31000/37647 utterances processed\n",
            "32000/37647 utterances processed\n",
            "33000/37647 utterances processed\n",
            "34000/37647 utterances processed\n",
            "35000/37647 utterances processed\n",
            "36000/37647 utterances processed\n",
            "37000/37647 utterances processed\n"
          ]
        }
      ],
      "source": [
        "from convokit import politenessStrategies\n",
        "ps = politenessStrategies.PolitenessStrategies(verbose = 1000)\n",
        "corpus = ps.fit_transform(corpus=corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cu0obz77BjV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKUovYMnA5Vb",
        "outputId": "b4cd93a2-0409-4bfc-cbc3-64bac9480ce3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "feature_politeness_==Please==                 0.015220\n",
              "feature_politeness_==Please_start==           0.028183\n",
              "feature_politeness_==HASHEDGE==               0.198528\n",
              "feature_politeness_==Indirect_(btw)==         0.000186\n",
              "feature_politeness_==Hedges==                 0.084841\n",
              "feature_politeness_==Factuality==             0.058889\n",
              "feature_politeness_==Deference==              0.014822\n",
              "feature_politeness_==Gratitude==              0.041783\n",
              "feature_politeness_==Apologizing==            0.008739\n",
              "feature_politeness_==1st_person_pl.==         0.068956\n",
              "feature_politeness_==1st_person==             0.251999\n",
              "feature_politeness_==1st_person_start==       0.201291\n",
              "feature_politeness_==2nd_person==             0.233724\n",
              "feature_politeness_==2nd_person_start==       0.053789\n",
              "feature_politeness_==Indirect_(greeting)==    0.009669\n",
              "feature_politeness_==Direct_question==        0.050416\n",
              "feature_politeness_==Direct_start==           0.088188\n",
              "feature_politeness_==HASPOSITIVE==            0.413393\n",
              "feature_politeness_==HASNEGATIVE==            0.345207\n",
              "feature_politeness_==SUBJUNCTIVE==            0.004330\n",
              "feature_politeness_==INDICATIVE==             0.003639\n",
              "dtype: float64"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps.summarize(corpus=corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "C7ocw_Al4wev",
        "outputId": "c012a609-9e25-4e4f-8c10-4573cb11b0f0"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-cf79f094e14b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(node, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0manytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCountError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExpecting\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0melements\u001b[0m \u001b[0mat\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;36m5.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/f/b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m...\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/f/b/d/e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36m_find\u001b[0;34m(node, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_findall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36m_findall\u001b[0;34m(node, filter_, stop, maxlevel, mincount, maxcount)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_findall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmincount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPreOrderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mresultlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmincount\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresultlen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmincount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/iterators/abstractiter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/iterators/preorderiter.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(children, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchild_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mAbstractIter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abort_at_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-cf79f094e14b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'name'"
          ]
        }
      ],
      "source": [
        "from anytree import Node, find\n",
        "corpus.get_utterance(\"iqp0hc8\")\n",
        "target_node = find(conversations_tree, lambda node: node.name == \"iqp0hc8\")\n",
        "print(target_node.body)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9YXWG1wnGcD",
        "outputId": "ab89344f-cdb9-4ec9-b90c-ef22a2d4a8b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvoKitMeta({})"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus.get_conversation(\"xsyg0d\").meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGpu-pED3O--"
      },
      "outputs": [],
      "source": [
        "def calculate_conversation_score(dataset_with_metrics_score, metrics_weights):\n",
        "  i = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYPNS6On_wnn"
      },
      "outputs": [],
      "source": [
        "file_path = base_path + 'train.tsv.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "yIS9H7VQ4EJu",
        "outputId": "d2041625-4c80-44a7-e87e-cdf927643340"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f94662d4721f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Read the lines and store them in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create a DataFrame from the lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-f94662d4721f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Read the lines and store them in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create a DataFrame from the lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the .tsv.tar.gz file\n",
        "\n",
        "# Open the .tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    # Extract the .tsv.gz file from the .tar.gz archive\n",
        "    tsv_file = tar.getmembers()[0]\n",
        "    file_extension = tsv_file.name.split('.')[-1]\n",
        "\n",
        "    # Check if the file is compressed\n",
        "    if file_extension == 'gz':\n",
        "        # Open the .tsv.gz file\n",
        "        with gzip.open(tar.extractfile(tsv_file), 'rt') as tsv:\n",
        "            # Read the lines and store them in a list\n",
        "            lines = [line.strip() for line in tsv]\n",
        "\n",
        "    else:\n",
        "        # Open the uncompressed .tsv file\n",
        "        with tar.extractfile(tsv_file) as tsv:\n",
        "            # Read the lines and store them in a list\n",
        "            lines = [line.decode().strip() for line in tsv]\n",
        "\n",
        "# Create a DataFrame from the lines\n",
        "df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "# Optionally, you can set the column names based on the first row\n",
        "df.columns = df.iloc[0]\n",
        "df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giecAWqb_nBx"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the .tsv.tar.gz file\n",
        "#file_path = 'path/to/your/file.tsv.tar.gz'\n",
        "\n",
        "# Specify the number of lines to read at a time\n",
        "batch_size = 1000\n",
        "\n",
        "# Open the .tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    # Extract the .tsv.gz file from the .tar.gz archive\n",
        "    tsv_file = tar.getmembers()[0]\n",
        "    file_extension = tsv_file.name.split('.')[-1]\n",
        "\n",
        "    # Check if the file is compressed\n",
        "    if file_extension == 'gz':\n",
        "        # Open the .tsv.gz file\n",
        "        with gzip.open(tar.extractfile(tsv_file), 'rt') as tsv:\n",
        "            # Read the lines in batches\n",
        "            lines = []\n",
        "            for line in tsv:\n",
        "                lines.append(line.strip())\n",
        "                if len(lines) == batch_size:\n",
        "                    # Process the lines and create a DataFrame\n",
        "                    df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "                    # Optionally, set the column names based on the first row\n",
        "                    df.columns = df.iloc[0]\n",
        "                    df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "                    # Do further processing with the DataFrame\n",
        "                    # ...\n",
        "\n",
        "                    # Clear the lines list to free memory\n",
        "                    lines = []\n",
        "\n",
        "            # Process the remaining lines\n",
        "            if lines:\n",
        "                df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df[1:]\n",
        "\n",
        "    else:\n",
        "        # Open the uncompressed .tsv file\n",
        "        with tar.extractfile(tsv_file) as tsv:\n",
        "            # Read the lines in batches\n",
        "            lines = []\n",
        "            for line in tsv:\n",
        "                lines.append(line.decode().strip())\n",
        "                if len(lines) == batch_size:\n",
        "                    # Process the lines and create a DataFrame\n",
        "                    df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "                    # Optionally, set the column names based on the first row\n",
        "                    df.columns = df.iloc[0]\n",
        "                    df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "                    # Do further processing with the DataFrame\n",
        "                    # ...\n",
        "                    print(df.columns)\n",
        "                    # Clear the lines list to free memory\n",
        "                    lines = []\n",
        "\n",
        "            # Process the remaining lines\n",
        "            if lines:\n",
        "                df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df[1:]\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNe3R85eyO8EF5TKQSa7QKk",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}