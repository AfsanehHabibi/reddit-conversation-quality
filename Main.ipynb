{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfsanehHabibi/reddit-conversation-quality/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nwsrw4kRxSO",
        "outputId": "f7d3cb6f-24dd-46aa-ae31-d89bbd0bb9a9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anytree\n",
            "  Downloading anytree-2.12.1-py3-none-any.whl (44 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.9/44.9 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.12.1\n"
          ]
        }
      ],
      "source": [
        "!pip install anytree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpq42XsomqOz",
        "outputId": "97d8bbe7-f45c-4ece-b35f-fc6596fe8e93"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langdetect\n",
            "  Downloading langdetect-1.0.9.tar.gz (981 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.7/981.5 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m553.0/981.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from langdetect) (1.16.0)\n",
            "Building wheels for collected packages: langdetect\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-py3-none-any.whl size=993224 sha256=4d9c0f01b12eaca0963817cd9aedd3dad5f2adebe0a61e9e1e7795a0b3b04d4b\n",
            "  Stored in directory: /root/.cache/pip/wheels/95/03/7d/59ea870c70ce4e5a370638b5462a7711ab78fba2f655d05106\n",
            "Successfully built langdetect\n",
            "Installing collected packages: langdetect\n",
            "Successfully installed langdetect-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install langdetect"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install  kili"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O5uUiR7-SVXY",
        "outputId": "0da59c78-6858-4761-e586-f5042a964bc5"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting kili\n",
            "  Downloading kili-2.148.3-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (1.5.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (2.31.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from kili) (0.9.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (8.2.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (4.66.1)\n",
            "Collecting typeguard<5,>=4 (from kili)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from kili) (4.5.0)\n",
            "Requirement already satisfied: pyparsing<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (3.1.1)\n",
            "Requirement already satisfied: websocket-client<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (1.6.4)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from kili) (6.0.1)\n",
            "Requirement already satisfied: Pillow<11.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (9.4.0)\n",
            "Collecting cuid<0.5,>=0.4 (from kili)\n",
            "  Downloading cuid-0.4.tar.gz (5.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from kili) (2.0.7)\n",
            "Collecting ffmpeg-python<0.3.0,>=0.2.0 (from kili)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting gql[requests,websockets]<4.0.0,>=3.5.0b5 (from kili)\n",
            "  Downloading gql-3.5.0b7-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.7/72.7 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (3.13.1)\n",
            "Collecting pyrate-limiter<3,>=2 (from kili)\n",
            "  Downloading pyrate_limiter-2.10.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python<0.3.0,>=0.2.0->kili) (0.18.3)\n",
            "Collecting graphql-core<3.4,>=3.3.0a3 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading graphql_core-3.3.0a3-py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.9/209.9 kB\u001b[0m \u001b[31m19.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (1.9.2)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting websockets<12,>=10 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-toolbelt<2,>=1.0.0 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (2023.7.22)\n",
            "Collecting typing-extensions<5.0.0,>=4.1.0 (from kili)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3.0.0,>=1.0.0->kili) (1.16.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (6.0.4)\n",
            "Building wheels for collected packages: cuid\n",
            "  Building wheel for cuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuid: filename=cuid-0.4-py2.py3-none-any.whl size=4712 sha256=2c18a4d57cca91891f3e766467bb872e29e403eae6a974f6777490a0923d0190\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/0a/dc/a0e28c435d5a74d9eef3d7c3cd147b96cb21e71e5ec7dcfdbe\n",
            "Successfully built cuid\n",
            "Installing collected packages: cuid, websockets, typing-extensions, pyrate-limiter, graphql-core, ffmpeg-python, backoff, typeguard, requests-toolbelt, gql, kili\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cuid-0.4 ffmpeg-python-0.2.0 gql-3.5.0b7 graphql-core-3.3.0a3 kili-2.148.3 pyrate-limiter-2.10.0 requests-toolbelt-1.0.0 typeguard-4.1.5 typing-extensions-4.8.0 websockets-11.0.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j5J5hYGGO0I0"
      },
      "outputs": [],
      "source": [
        "#!pip3 install convokit\n",
        "#!python3 -m spacy download en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2nKEu6z62yR",
        "outputId": "cb8f4ad2-87dc-4d7e-84fb-52b13320b24e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_70YRYLYNso"
      },
      "source": [
        "#Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "g3cAemLLTz6h"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import json\n",
        "from anytree import Node, RenderTree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "WF_hZIxO64-f"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/University/RedditData/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ZHFK04u4W1_r"
      },
      "outputs": [],
      "source": [
        "def extract_files_list(file_list_path):\n",
        "    files_name = []\n",
        "    with open(file_list_path, 'r') as file_list:\n",
        "        for line in file_list:\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                file_path, _ = line.split(',')\n",
        "                files_name.append(file_path)\n",
        "    return files_name"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wxmCIBekXfCX"
      },
      "outputs": [],
      "source": [
        "data_files_name = extract_files_list(f\"{base_path}timestamps_seed2_num20_period10_date2022-10-1.txt_comments_progress.txt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "tZTRmfusY7K4"
      },
      "outputs": [],
      "source": [
        "def make_submission_file_path(file_name):\n",
        "    return f\"{base_path}submissions_{file_name}.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ybXnmbWIgl-D"
      },
      "outputs": [],
      "source": [
        "def make_comment_file_path(file_name):\n",
        "    return f\"{base_path}comments_{file_name}.json\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "36MQkOALazZV"
      },
      "outputs": [],
      "source": [
        "subreddits = set()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "-EDIPZXzYJjf"
      },
      "outputs": [],
      "source": [
        "def extract_submissions_text_with_filter(data_files_name):\n",
        "    submissions_dic = {}\n",
        "    over_18_count = 0\n",
        "    for file_name in data_files_name:\n",
        "        file_path = make_submission_file_path(file_name)\n",
        "        with open(file_path, 'r') as file:\n",
        "            lines_sub = file.readlines()\n",
        "        for l in lines_sub:\n",
        "            obj = json.loads(l)\n",
        "            if obj['over_18'] == False:\n",
        "                submissions_dic[obj['id']]  = obj['title'] + obj['selftext']\n",
        "                subreddits.add(obj['subreddit'])\n",
        "            else:\n",
        "                over_18_count += 1\n",
        "    print(\"over 18 count \", over_18_count)\n",
        "    return submissions_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PyrYu-8qbO9i",
        "outputId": "061feff1-12c8-4961-c8ec-8e4e8493d465"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "over 18 count  66876\n"
          ]
        }
      ],
      "source": [
        "subsmissions = extract_submissions_text_with_filter(data_files_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zzw-iWqGcN8J",
        "outputId": "f0c79c0e-5ac9-4978-ca3e-941242376d3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "96333"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "len(subsmissions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-gatXoaOEzjc"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def count_comments_in_file(file_path):\n",
        "    count = 0\n",
        "    with open(file_path, 'r') as json_file:\n",
        "        lines = json_file.readlines()\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            count += len(data.get('comments', []))\n",
        "    return count\n",
        "\n",
        "def total_comments_in_files(file_list_path):\n",
        "    total_comments = 0\n",
        "    with open(file_list_path, 'r') as file_list:\n",
        "        for line in file_list:\n",
        "            print(line)\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                file_path, _ = line.split(',')\n",
        "                total_comments += count_comments_in_file(f\"{base_path}comments_{file_path}.json\")\n",
        "    return total_comments\n",
        "\n",
        "# Replace 'file_list.txt' with the path to your text file containing the list of file names\n",
        "#total_comments = total_comments_in_files(f\"{base_path}timestamps_seed2_num20_period10_date2022-10-1.txt_comments_progress.txt\")\n",
        "#print(f'Total number of comments in the files: {total_comments}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "5v3l38OFerIb"
      },
      "outputs": [],
      "source": [
        "def load_comments_with_filter(files_name, submmissions):\n",
        "    # Create a dictionary to store the comment nodes by their IDs\n",
        "    conversations_dic = {}\n",
        "    for file_name in data_files_name:\n",
        "        comment_file = make_comment_file_path(file_name)\n",
        "        with open(comment_file, 'r') as file:\n",
        "            lines = file.readlines()\n",
        "\n",
        "        for line in lines:\n",
        "            comment_nodes = {}\n",
        "            json_obj = json.loads(line)\n",
        "            submission_id = json_obj['submission_id']\n",
        "            comments = json_obj['comments']\n",
        "            if len(comments) == 0:\n",
        "              continue\n",
        "            if submission_id not in subsmissions:\n",
        "                #submission has removed in preprocessing\n",
        "                continue\n",
        "            flat_comments_list = []\n",
        "            parent_child_pairs = []\n",
        "            # Create root node for the submission\n",
        "            submission_text = subsmissions[submission_id]\n",
        "            root = Node(submission_id, body = submission_text)\n",
        "            comment_nodes[submission_id] = root\n",
        "            conversation_text = submission_text\n",
        "            flat_comments_list.append({'id': submission_id, 'body': submission_text, 'author':None, 'reply_to':None, 'conversation_id':submission_id})\n",
        "            # Create child nodes for the comments\n",
        "            for comment in comments:\n",
        "                # Check if comment is from a bot and ignore it if it is\n",
        "                if \"I am a bot, and this action was performed automatically\" in comment['body']:\n",
        "                    continue\n",
        "\n",
        "                comment_id = comment['id']\n",
        "                author = comment.get('author_fullname', 'unknown')\n",
        "                parent_id = comment['parent_id'].split('_', 1)[-1]\n",
        "                body = comment['body']\n",
        "                comment_node = Node(comment_id, body=body)\n",
        "\n",
        "                if parent_id in comment_nodes:\n",
        "                    flat_comments_list.append({'id': comment_id, 'body': body, 'author':author, 'reply_to':parent_id, 'conversation_id':submission_id})\n",
        "                    parent_node = comment_nodes[parent_id]\n",
        "                    parent_child_pairs.append({\n",
        "                        'comment': parent_node.body,\n",
        "                        'reply': body,\n",
        "                        'comment_id': parent_node.name,\n",
        "                        'reply_id': comment_id,\n",
        "                        'global_id': parent_node.name + \"_\" + comment_id\n",
        "                    })\n",
        "                    comment_node.parent = parent_node\n",
        "                    conversation_text += \"/n\"+ body\n",
        "                    comment_nodes[comment_id] = comment_node\n",
        "            # Print the tree structure\n",
        "            # print(RenderTree(root))\n",
        "            conversations_dic[submission_id] = {\n",
        "                'tree': root,\n",
        "                'full_text': conversation_text,\n",
        "                'pairs': parent_child_pairs,\n",
        "                'comments': flat_comments_list\n",
        "            }\n",
        "            #for parent in root.children:\n",
        "            #  for child in parent.children:\n",
        "            #       parent_child_pairs.append((parent.body, child.body))\n",
        "\n",
        "            # Print the parent-child pairs\n",
        "            #for pair in parent_child_pairs:\n",
        "            #   print(f\"Parent: {pair[0]}, Child: {pair[1]}\")\n",
        "\n",
        "            # Print the tree structure\n",
        "            #for pre, fill, node in RenderTree(root):\n",
        "            #   print(f\"{pre}{node.name}\")\n",
        "\n",
        "        #print(RenderTree(conversations_tree[2555]))\n",
        "    return conversations_dic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "DKtZ62JIixvx"
      },
      "outputs": [],
      "source": [
        "conversations_dic = load_comments_with_filter(data_files_name, subsmissions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffWeiRW-j-Ij",
        "outputId": "279981d7-e04d-4799-ec4c-b2f2b787d6b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39784"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ],
      "source": [
        "len(conversations_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "HmgKU0v5yaGw"
      },
      "outputs": [],
      "source": [
        "def filter_empty_conversations(conversations_dic):\n",
        "  non_empty_conversations = {}\n",
        "  for id in conversations_dic:\n",
        "    new_pairs = []\n",
        "    pairs = conversations_dic[id]['pairs']\n",
        "    for pair in pairs:\n",
        "      if not(pair['comment'] == '[deleted]' or pair['reply'] == '[deleted]' or pair['comment'].endswith('[removed]')):\n",
        "        new_pairs.append(pair)\n",
        "    if len(new_pairs) > 0:\n",
        "      conversations_dic[id]['pairs'] = new_pairs\n",
        "      non_empty_conversations[id] = conversations_dic[id]\n",
        "  return non_empty_conversations\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ZLG3P45O53NQ"
      },
      "outputs": [],
      "source": [
        "non_empty_conversations = filter_empty_conversations(conversations_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKb3hWFm-IW6",
        "outputId": "ecca1009-4813-4912-d0e3-955c8afd3717"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39784"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "len(conversations_dic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X8KEfKfH-GQP",
        "outputId": "dfeacb6f-7c28-4a3e-af7b-ddf59c0e8a87"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "35393"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "len(non_empty_conversations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "w4c4sbU4nK5_"
      },
      "outputs": [],
      "source": [
        "from langdetect import detect, LangDetectException\n",
        "\n",
        "def filter_non_english(conversations_dic):\n",
        "    english_conversations = {}\n",
        "    for id in conversations_dic:\n",
        "        try:\n",
        "            language = detect(conversations_dic[id]['full_text'])\n",
        "            if language == 'en':\n",
        "                english_conversations[id] = conversations_dic[id]\n",
        "        except LangDetectException as e:\n",
        "            # Handle the exception and print the problematic input\n",
        "            # print(f\"Language detection error for comment: {conversations_dic[id]['full_text']}\")\n",
        "            continue\n",
        "    return english_conversations"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "nD_P8W5qWsHb"
      },
      "outputs": [],
      "source": [
        "english_conversations = filter_non_english(non_empty_conversations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yk6xYJSqWz0y",
        "outputId": "6c1c6222-74fe-4581-b663-94c727d21b4e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33566"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "len(english_conversations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RwV-WRFiQHxf",
        "outputId": "aeee6a18-1fd8-4638-8a31-bd7d10b430c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The text contains a question.\n"
          ]
        }
      ],
      "source": [
        "import re\n",
        "\n",
        "def contains_question(text):\n",
        "    # Check if the text contains a question mark\n",
        "    if '?' in text:\n",
        "        return True\n",
        "\n",
        "    # Check if the text contains certain question words\n",
        "    question_words = ['what', 'how', 'when', 'where', 'who', 'why']\n",
        "    for word in question_words:\n",
        "        if re.search(r'\\b{}\\b'.format(word), text, re.IGNORECASE):\n",
        "            return True\n",
        "\n",
        "    # Check if the text contains the word \"please\"\n",
        "    if re.search(r'\\bplease\\b', text, re.IGNORECASE):\n",
        "        return True\n",
        "\n",
        "    # If none of the above conditions are met, return False\n",
        "    return False\n",
        "\n",
        "# Example usage\n",
        "text = \"What is the capital of France? I love Paris. How do you make a cake? The recipe is easy to follow. Can you please pass the salt?\"\n",
        "if contains_question(text):\n",
        "    print(\"The text contains a question.\")\n",
        "else:\n",
        "    print(\"The text does not contain a question.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGRc-uliMFrf",
        "outputId": "67d69185-350d-4460-fc27-4cb19fae932f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "comment: Meet up before the show?Hey, guys! Very much looking forward to these Red Rocks shows! I know it's been asked a lot on here already but would anyone be interested in meeting up for a drink on Saturday or Monday before the show? \n",
            "\n",
            "I work a ton and won't be able to make it to the meetup on Sunday...\n",
            "reply: Yes! I’ll PM you!!\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "random_pair = random.choice(list(english_conversations.items()))\n",
        "for pair in random_pair[1]['pairs']:\n",
        "  print(contains_question(pair['comment']))\n",
        "  print(\"comment:\", pair['comment'])\n",
        "  print(\"reply:\", pair['reply'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "omP3WZ5Rcflz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1abe7035-61c5-46d2-e955-de389c0ecbb0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-0df81c083ef2>:9: DeprecationWarning: Sampling from a set deprecated\n",
            "since Python 3.9 and will be removed in a subsequent version.\n",
            "  random_sample = random.sample(english_conversations.items(), sample_size)\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# Define the sample size (e.g., 3 for a sample of 3 elements)\n",
        "sample_size = 100\n",
        "random_pairs = []\n",
        "\n",
        "# Use random.sample to get a random sample of the specified size\n",
        "random_sample = random.sample(english_conversations.items(), sample_size)\n",
        "for sample_conversation in random_sample:\n",
        "    random_pair = random.choice(sample_conversation[1]['pairs'])\n",
        "    random_pairs.append(random_pair)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "V7RkZbfQdOuv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f48bd2d3-6876-4669-bbc9-bd17956ebeb1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "len(random_pairs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "1CjlutGLdVOM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30a730e0-f251-4032-e34a-f54fd23fdffb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'comment': 'Does not make it okay, does it?',\n",
              "  'reply': '“it’s not okay.” is about the worst argument that anyone can come up with in relation to literally any problem.',\n",
              "  'comment_id': 'iqz6fvw',\n",
              "  'reply_id': 'iqz94rp',\n",
              "  'global_id': 'iqz6fvw_iqz94rp'},\n",
              " {'comment': 'TrueNAS + Plex: How do get Plex to see my files?Apologies if this is not the correct subreddit.\\n\\nI have Plex set up through my TrueNAS server. I have two pools - GLaDOS and tank. GLaDOS holds the media files (movies ,tv shows, music), and tank holds the jail for Plex.\\n\\nI have mount points set up to create a link between tank and GLaDOS so that way Plex sees the folders for the libraries. I also had to give full access to @everyone in order for this to happen.\\n\\nNow, Plex sees the media folders- and it sees the files inside of the folders, but when I perform a library scan - it does not populate the Plex files in the library.\\nHere is an [imgur album](https://imgur.com/a/NurYIOc) of what I am describing. \\n\\nHow do I get Plex to see these files in a way where they will show in the library?\\n\\nThank you for the help and assistance.',\n",
              "  'reply': 'The first thing coming to my mind is permissions and ownership issues. While Plex can see the files it might not be able to read them.\\n\\nThe other thing is your naming convention. Name your files correctly and you will prevent a lot of problems down the road.\\n\\nhttps://support.plex.tv/articles/naming-and-organizing-your-movie-media-files/',\n",
              "  'comment_id': 'xslf5y',\n",
              "  'reply_id': 'iqlcs15',\n",
              "  'global_id': 'xslf5y_iqlcs15'},\n",
              " {'comment': \"fafsaso if i know that i'm getting full tuition covered in state through national merit (benequisto for fl) then do i still have to list in state schools cause i don't have enough space\",\n",
              "  'reply': 'You can submit an edit to the FAFSA later that adds more schools - they provide instructions at the below link.\\n\\nhttps://studentaid.gov/help/more-ten-colleges',\n",
              "  'comment_id': 'xsyegf',\n",
              "  'reply_id': 'iqmvyao',\n",
              "  'global_id': 'xsyegf_iqmvyao'},\n",
              " {'comment': 'smile🙂',\n",
              "  'reply': 'God awful post',\n",
              "  'comment_id': 'xy5x13',\n",
              "  'reply_id': 'irgbc78',\n",
              "  'global_id': 'xy5x13_irgbc78'},\n",
              " {'comment': \"'Gladio': The clandestine military network operating on European soil for 40 years\",\n",
              "  'reply': \"Its an interesting question with regard to the overlap of UK's Jeremy Corbyn, earlier Labour Party leader and Gladio.  It seemed that the criticism of his every move, every breath, in the mainstream press and concerted efforts to bring him down were unprecedented and strange in their degree of obsession.\",\n",
              "  'comment_id': 'xuax42',\n",
              "  'reply_id': 'iqvlajw',\n",
              "  'global_id': 'xuax42_iqvlajw'}]"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "random_pairs[:5]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVwzZgyHdRg8",
        "outputId": "a5eca8d1-bb76-46e8-de06-9eab63ff0342"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Project ID:  clp5nrlic1ttw086r5wneguxa\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "from kili.client import Kili\n",
        "kili = Kili(api_key='6acd489f-9746-4ac4-9650-54e2d9c9faba')\n",
        "interface = {\n",
        "    \"jobs\": {\n",
        "        \"JOB_0\": {\n",
        "            \"mlTask\": \"CLASSIFICATION\",\n",
        "            \"required\": 1,\n",
        "            \"isChild\": False,\n",
        "            \"content\": {\n",
        "                \"categories\": {\"Related\": {\"name\": \"is relevent\"}, \"UnRelated\": {\"name\": \"is not relevent\"}},\n",
        "                \"input\": \"radio\",\n",
        "            },\n",
        "        },\n",
        "        \"JOB_1\": {\n",
        "            \"mlTask\": \"CLASSIFICATION\",\n",
        "            \"required\": 1,\n",
        "            \"isChild\": False,\n",
        "            \"content\": {\n",
        "                \"categories\": {\"HasQuality\": {\"name\": \"has quality: does not say which it lack adequate evidence or it believes to be false.\"}, \"NonQuality\": {\"name\": \"no quality: says which it lacks evidence or it believes is false.\"}},\n",
        "                \"input\": \"radio\",\n",
        "            },\n",
        "        },\n",
        "        \"JOB_2\": {\n",
        "            \"mlTask\": \"CLASSIFICATION\",\n",
        "            \"required\": 1,\n",
        "            \"isChild\": False,\n",
        "            \"content\": {\n",
        "                \"categories\": {\"HasQuantity\": {\"name\": \"has quantity: is as informative as is required\"}, \"NoQuantity\": {\"name\": \"no  quantity: is more or less informative than is required\"}},\n",
        "                \"input\": \"radio\",\n",
        "            },\n",
        "        },\n",
        "        \"JOB_3\": {\n",
        "            \"mlTask\": \"CLASSIFICATION\",\n",
        "            \"required\": 1,\n",
        "            \"isChild\": False,\n",
        "            \"content\": {\n",
        "                \"categories\": {\"HasManner\": {\"name\": \"has manner: avoids vagueness, avoids ambiguty, do not play with words, is orderly\"}, \"NoManner\": {\"name\": \"no manner: is vague or ambiguous or plays with words or is not orderly\"}},\n",
        "                \"input\": \"radio\",\n",
        "            },\n",
        "        },\n",
        "        \"JOB_4\": {\n",
        "            \"mlTask\": \"CLASSIFICATION\",\n",
        "            \"required\": 1,\n",
        "            \"isChild\": False,\n",
        "            \"content\": {\n",
        "                \"categories\": {\"IsPolite\": {\"name\": \"is polite\"}, \"NotPolite\": {\"name\": \"is not polite\"}},\n",
        "                \"input\": \"radio\",\n",
        "            },\n",
        "        }\n",
        "    }\n",
        "}\n",
        "\n",
        "project = kili.create_project(\n",
        "    title=\"Testing 2...\",\n",
        "    description=\"Project Description\",\n",
        "    input_type=\"TEXT\",\n",
        "    json_interface=interface,\n",
        ")\n",
        "project_id = project['id']\n",
        "print(\"Project ID: \", project_id)\n",
        "assets = kili.append_many_to_dataset(\n",
        "    project_id=project_id,\n",
        "    content_array = [('comment: ' + d['comment'] + '\\n' + 'reply: ' + d['reply']) for d in random_pairs[:3]],\n",
        "    external_id_array = [d['global_id'] for d in random_pairs[:3]]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gz-OYtq6-iuo",
        "outputId": "4cf48f7b-27be-4fb9-c680-2f3eb6198c8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "iqmyeuo: Hey, we launched a new music-scanning feature at Soundslice just a few days ago ([see here](https://www.soundslice.com/blog/226/pdf-and-photo-scanning-beta/)). It uses artificial intelligence to convert PDFs/images into editable sheet music.\n",
            "\n",
            "I'm happy to run a PDF through it for you if you'd like — just send me a DM!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[Node('/xsyewi', body=\"Has Anyone Tried Scanscore ?I've been trying to find a pdf scanner app or program that can scan sheet music and turn it into a **musicxml** format. I came across Scanscore, but I don't if it's any good. anyone in this sub try it? would you recommend it?\")]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import random\n",
        "\n",
        "\n",
        "# Define the sample size (e.g., 3 for a sample of 3 elements)\n",
        "sample_size = 1\n",
        "\n",
        "# Use random.sample to get a random sample of the specified size\n",
        "random_sample = random.sample(conversations_tree, sample_size)\n",
        "from anytree import PreOrderIter\n",
        "\n",
        "# Assuming 'root' is the root node of the conversation tree\n",
        "for node in PreOrderIter(random_sample[0]):\n",
        "    if node.parent is not None:\n",
        "        print(f\"{node.name}: {node.body}\")\n",
        "\n",
        "random_sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "jzvR0YnpSdWM",
        "outputId": "fbfba739-ce62-4c8d-f8c2-238995635e12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting kili\n",
            "  Downloading kili-2.148.1-py3-none-any.whl (288 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.7/288.7 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (1.5.3)\n",
            "Requirement already satisfied: click<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (8.1.7)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (2.31.0)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from kili) (0.9.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (8.2.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (4.66.1)\n",
            "Collecting typeguard<5,>=4 (from kili)\n",
            "  Downloading typeguard-4.1.5-py3-none-any.whl (34 kB)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.1.0 in /usr/local/lib/python3.10/dist-packages (from kili) (4.5.0)\n",
            "Requirement already satisfied: pyparsing<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (3.1.1)\n",
            "Requirement already satisfied: websocket-client<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (1.6.4)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from kili) (6.0.1)\n",
            "Requirement already satisfied: Pillow<11.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (9.4.0)\n",
            "Collecting cuid<0.5,>=0.4 (from kili)\n",
            "  Downloading cuid-0.4.tar.gz (5.0 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: urllib3<3,>=1.26 in /usr/local/lib/python3.10/dist-packages (from kili) (2.0.7)\n",
            "Collecting ffmpeg-python<0.3.0,>=0.2.0 (from kili)\n",
            "  Downloading ffmpeg_python-0.2.0-py3-none-any.whl (25 kB)\n",
            "Collecting gql[requests,websockets]<4.0.0,>=3.5.0b5 (from kili)\n",
            "  Downloading gql-3.5.0b6-py2.py3-none-any.whl (72 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.6/72.6 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock<4.0.0,>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from kili) (3.13.1)\n",
            "Collecting pyrate-limiter<3,>=2 (from kili)\n",
            "  Downloading pyrate_limiter-2.10.0-py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from ffmpeg-python<0.3.0,>=0.2.0->kili) (0.18.3)\n",
            "Collecting graphql-core<3.4,>=3.3.0a3 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading graphql_core-3.3.0a3-py3-none-any.whl (209 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.9/209.9 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: yarl<2.0,>=1.6 in /usr/local/lib/python3.10/dist-packages (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (1.9.2)\n",
            "Collecting backoff<3.0,>=1.11.1 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Collecting requests-toolbelt<2,>=1.0.0 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12,>=10 (from gql[requests,websockets]<4.0.0,>=3.5.0b5->kili)\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0.0,>=1.0.0->kili) (1.23.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.0.0->kili) (2023.7.22)\n",
            "Collecting typing-extensions<5.0.0,>=4.1.0 (from kili)\n",
            "  Downloading typing_extensions-4.8.0-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas<3.0.0,>=1.0.0->kili) (1.16.0)\n",
            "Requirement already satisfied: multidict>=4.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.6->gql[requests,websockets]<4.0.0,>=3.5.0b5->kili) (6.0.4)\n",
            "Building wheels for collected packages: cuid\n",
            "  Building wheel for cuid (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for cuid: filename=cuid-0.4-py2.py3-none-any.whl size=4712 sha256=b59c7136e6a0c35c44357a37f14df5f03d3a688b3754ee601d531698bd5923bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/52/0a/dc/a0e28c435d5a74d9eef3d7c3cd147b96cb21e71e5ec7dcfdbe\n",
            "Successfully built cuid\n",
            "Installing collected packages: cuid, websockets, typing-extensions, pyrate-limiter, graphql-core, ffmpeg-python, backoff, typeguard, requests-toolbelt, gql, kili\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.8.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 cuid-0.4 ffmpeg-python-0.2.0 gql-3.5.0b6 graphql-core-3.3.0a3 kili-2.148.1 pyrate-limiter-2.10.0 requests-toolbelt-1.0.0 typeguard-4.1.5 typing-extensions-4.8.0 websockets-11.0.3\n"
          ]
        }
      ],
      "source": [
        "!pip install  kili"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "udPeZAdjp0hd",
        "outputId": "2db17f27-bb07-4f36-95f7-00e31d48393f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Parent: iqmum2s, Child: iqmunnz\n",
            "Parent: iqmum2s, Child: iqmuns8\n",
            "Parent: iqon7tc, Child: iqrmqmy\n",
            "xsy76f\n",
            "├── iqmum2s\n",
            "│   ├── iqmunnz\n",
            "│   └── iqmuns8\n",
            "├── iqob6q0\n",
            "└── iqon7tc\n",
            "    └── iqrmqmy\n",
            "        └── iqsvfoq\n"
          ]
        }
      ],
      "source": [
        "from anytree import Node, RenderTree\n",
        "\n",
        "# Create a list to store parent-child pairs\n",
        "parent_child_pairs = []\n",
        "\n",
        "# Access child nodes from the parent node and add the pairs to the list\n",
        "for parent in root.children:\n",
        "    for child in parent.children:\n",
        "        parent_child_pairs.append((parent.name, child.name))\n",
        "\n",
        "# Print the parent-child pairs\n",
        "for pair in parent_child_pairs:\n",
        "    print(f\"Parent: {pair[0]}, Child: {pair[1]}\")\n",
        "\n",
        "# Print the tree structure\n",
        "for pre, fill, node in RenderTree(root):\n",
        "    print(f\"{pre}{node.name}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m4brlEl0nruv",
        "outputId": "3d358491-66e0-46dd-aa34-c916afe67658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been prepared for Kili labeling.\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "\n",
        "for comment in flat_comments_list:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJJSGUQj3m46"
      },
      "outputs": [],
      "source": [
        "formatted_data = []\n",
        "for comment in flat_comments_list:\n",
        "    formatted_comment = {\n",
        "        \"row_data\": comment['body'],\n",
        "        \"global_key\": comment['id'],\n",
        "        \"media_type\": \"TEXT\",\n",
        "        \"metadata_fields\": [],\n",
        "        \"attachments\": []\n",
        "    }\n",
        "    formatted_data.append(formatted_comment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LTQdXVen1Esj",
        "outputId": "b6f9e540-0d9b-491c-c361-9fa3cf5c0db5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data has been written to formatted_comments.json\n"
          ]
        }
      ],
      "source": [
        "with open(base_path +\"flat_comments_list.json\", \"w\") as json_file:\n",
        "    json.dump(flat_comments_list, json_file, indent=2)\n",
        "\n",
        "print(\"Data has been written to formatted_comments.json\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T62FjApSor6r"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "evaEvX_QopHZ",
        "outputId": "3c2a8a3f-c192-40a4-8e41-d36401970bda"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-3beb6b0771e2>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconversations_tree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: 0 is not in list"
          ]
        }
      ],
      "source": [
        "conversations_tree.index(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LSeMoQFZQ5Ze"
      },
      "outputs": [],
      "source": [
        "def flatten_tree(node, flattened_tree):\n",
        "    flattened_tree.append(node)\n",
        "    for child in node.children:\n",
        "        flatten_tree(child, flattened_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EWwi-EwdPwJe"
      },
      "outputs": [],
      "source": [
        "flattened_tree = []\n",
        "flatten_tree(root, flattened_tree)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0WMaY9uoli3",
        "outputId": "a26dd0d8-6816-4e35-e071-81b5b7904cfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<function __main__.flatten_tree(node, flattened_tree)>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "flatten_tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jbP4uSHiRw_k"
      },
      "outputs": [],
      "source": [
        "# there is node without body!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NwRWOf09RWQr"
      },
      "outputs": [],
      "source": [
        "from convokit import Corpus, Utterance, Speaker\n",
        "# Create a Corpus object from the flattened tree.\n",
        "corpus = Corpus(utterances=[\n",
        "        Utterance(id=node['id'], text=node['body'], speaker=Speaker(id = node['author']), reply_to=node['reply_to'], conversation_id=node['conversation_id'])\n",
        "        for node in flat_comments_list\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "TEEuPkkmsWXD",
        "outputId": "c4d6035d-67b6-49bd-c138-e3abaa53e4bf"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-fe0bc8cfc776>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Corpus' object has no attribute 'fit'"
          ]
        }
      ],
      "source": [
        "corpus = corpus.fit(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t26-KJvk3WN",
        "outputId": "0f8803fa-fb8e-4e86-8191-0a0a0d576961"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2940\n"
          ]
        }
      ],
      "source": [
        "counter = 0\n",
        "for convo in corpus.iter_conversations():\n",
        "    counter+=1\n",
        "print(counter)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b__m1fESn2QW",
        "outputId": "bcb5b6bd-2d9b-4f77-de14-cb0966adfd08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Number of Speakers: 20381\n",
            "Number of Utterances: 37647\n",
            "Number of Conversations: 2940\n"
          ]
        }
      ],
      "source": [
        "corpus.print_summary_stats()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGmGvNjMtr_1",
        "outputId": "07a02ab5-ba26-4d39-95b3-8b80de0e63f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "100/37647 utterances processed\n",
            "200/37647 utterances processed\n",
            "300/37647 utterances processed\n",
            "400/37647 utterances processed\n",
            "500/37647 utterances processed\n",
            "600/37647 utterances processed\n",
            "700/37647 utterances processed\n",
            "800/37647 utterances processed\n",
            "900/37647 utterances processed\n",
            "1000/37647 utterances processed\n",
            "1100/37647 utterances processed\n",
            "1200/37647 utterances processed\n",
            "1300/37647 utterances processed\n",
            "1400/37647 utterances processed\n",
            "1500/37647 utterances processed\n",
            "1600/37647 utterances processed\n",
            "1700/37647 utterances processed\n",
            "1800/37647 utterances processed\n",
            "1900/37647 utterances processed\n",
            "2000/37647 utterances processed\n",
            "2100/37647 utterances processed\n",
            "2200/37647 utterances processed\n",
            "2300/37647 utterances processed\n",
            "2400/37647 utterances processed\n",
            "2500/37647 utterances processed\n",
            "2600/37647 utterances processed\n",
            "2700/37647 utterances processed\n",
            "2800/37647 utterances processed\n",
            "2900/37647 utterances processed\n",
            "3000/37647 utterances processed\n",
            "3100/37647 utterances processed\n",
            "3200/37647 utterances processed\n",
            "3300/37647 utterances processed\n",
            "3400/37647 utterances processed\n",
            "3500/37647 utterances processed\n",
            "3600/37647 utterances processed\n",
            "3700/37647 utterances processed\n",
            "3800/37647 utterances processed\n",
            "3900/37647 utterances processed\n",
            "4000/37647 utterances processed\n",
            "4100/37647 utterances processed\n",
            "4200/37647 utterances processed\n",
            "4300/37647 utterances processed\n",
            "4400/37647 utterances processed\n",
            "4500/37647 utterances processed\n",
            "4600/37647 utterances processed\n",
            "4700/37647 utterances processed\n",
            "4800/37647 utterances processed\n",
            "4900/37647 utterances processed\n",
            "5000/37647 utterances processed\n",
            "5100/37647 utterances processed\n",
            "5200/37647 utterances processed\n",
            "5300/37647 utterances processed\n",
            "5400/37647 utterances processed\n",
            "5500/37647 utterances processed\n",
            "5600/37647 utterances processed\n",
            "5700/37647 utterances processed\n",
            "5800/37647 utterances processed\n",
            "5900/37647 utterances processed\n",
            "6000/37647 utterances processed\n",
            "6100/37647 utterances processed\n",
            "6200/37647 utterances processed\n",
            "6300/37647 utterances processed\n",
            "6400/37647 utterances processed\n",
            "6500/37647 utterances processed\n",
            "6600/37647 utterances processed\n",
            "6700/37647 utterances processed\n",
            "6800/37647 utterances processed\n",
            "6900/37647 utterances processed\n",
            "7000/37647 utterances processed\n",
            "7100/37647 utterances processed\n",
            "7200/37647 utterances processed\n",
            "7300/37647 utterances processed\n",
            "7400/37647 utterances processed\n",
            "7500/37647 utterances processed\n",
            "7600/37647 utterances processed\n",
            "7700/37647 utterances processed\n",
            "7800/37647 utterances processed\n",
            "7900/37647 utterances processed\n",
            "8000/37647 utterances processed\n",
            "8100/37647 utterances processed\n",
            "8200/37647 utterances processed\n",
            "8300/37647 utterances processed\n",
            "8400/37647 utterances processed\n",
            "8500/37647 utterances processed\n",
            "8600/37647 utterances processed\n",
            "8700/37647 utterances processed\n",
            "8800/37647 utterances processed\n",
            "8900/37647 utterances processed\n",
            "9000/37647 utterances processed\n",
            "9100/37647 utterances processed\n",
            "9200/37647 utterances processed\n",
            "9300/37647 utterances processed\n",
            "9400/37647 utterances processed\n",
            "9500/37647 utterances processed\n",
            "9600/37647 utterances processed\n",
            "9700/37647 utterances processed\n",
            "9800/37647 utterances processed\n",
            "9900/37647 utterances processed\n",
            "10000/37647 utterances processed\n",
            "10100/37647 utterances processed\n",
            "10200/37647 utterances processed\n",
            "10300/37647 utterances processed\n",
            "10400/37647 utterances processed\n",
            "10500/37647 utterances processed\n",
            "10600/37647 utterances processed\n",
            "10700/37647 utterances processed\n",
            "10800/37647 utterances processed\n",
            "10900/37647 utterances processed\n",
            "11000/37647 utterances processed\n",
            "11100/37647 utterances processed\n",
            "11200/37647 utterances processed\n",
            "11300/37647 utterances processed\n",
            "11400/37647 utterances processed\n",
            "11500/37647 utterances processed\n",
            "11600/37647 utterances processed\n",
            "11700/37647 utterances processed\n",
            "11800/37647 utterances processed\n",
            "11900/37647 utterances processed\n",
            "12000/37647 utterances processed\n",
            "12100/37647 utterances processed\n",
            "12200/37647 utterances processed\n",
            "12300/37647 utterances processed\n",
            "12400/37647 utterances processed\n",
            "12500/37647 utterances processed\n",
            "12600/37647 utterances processed\n",
            "12700/37647 utterances processed\n",
            "12800/37647 utterances processed\n",
            "12900/37647 utterances processed\n",
            "13000/37647 utterances processed\n",
            "13100/37647 utterances processed\n",
            "13200/37647 utterances processed\n",
            "13300/37647 utterances processed\n",
            "13400/37647 utterances processed\n",
            "13500/37647 utterances processed\n",
            "13600/37647 utterances processed\n",
            "13700/37647 utterances processed\n",
            "13800/37647 utterances processed\n",
            "13900/37647 utterances processed\n",
            "14000/37647 utterances processed\n",
            "14100/37647 utterances processed\n",
            "14200/37647 utterances processed\n",
            "14300/37647 utterances processed\n",
            "14400/37647 utterances processed\n",
            "14500/37647 utterances processed\n",
            "14600/37647 utterances processed\n",
            "14700/37647 utterances processed\n",
            "14800/37647 utterances processed\n",
            "14900/37647 utterances processed\n",
            "15000/37647 utterances processed\n",
            "15100/37647 utterances processed\n",
            "15200/37647 utterances processed\n",
            "15300/37647 utterances processed\n",
            "15400/37647 utterances processed\n",
            "15500/37647 utterances processed\n",
            "15600/37647 utterances processed\n",
            "15700/37647 utterances processed\n",
            "15800/37647 utterances processed\n",
            "15900/37647 utterances processed\n",
            "16000/37647 utterances processed\n",
            "16100/37647 utterances processed\n",
            "16200/37647 utterances processed\n",
            "16300/37647 utterances processed\n",
            "16400/37647 utterances processed\n",
            "16500/37647 utterances processed\n",
            "16600/37647 utterances processed\n",
            "16700/37647 utterances processed\n",
            "16800/37647 utterances processed\n",
            "16900/37647 utterances processed\n",
            "17000/37647 utterances processed\n",
            "17100/37647 utterances processed\n",
            "17200/37647 utterances processed\n",
            "17300/37647 utterances processed\n",
            "17400/37647 utterances processed\n",
            "17500/37647 utterances processed\n",
            "17600/37647 utterances processed\n",
            "17700/37647 utterances processed\n",
            "17800/37647 utterances processed\n",
            "17900/37647 utterances processed\n",
            "18000/37647 utterances processed\n",
            "18100/37647 utterances processed\n",
            "18200/37647 utterances processed\n",
            "18300/37647 utterances processed\n",
            "18400/37647 utterances processed\n",
            "18500/37647 utterances processed\n",
            "18600/37647 utterances processed\n",
            "18700/37647 utterances processed\n",
            "18800/37647 utterances processed\n",
            "18900/37647 utterances processed\n",
            "19000/37647 utterances processed\n",
            "19100/37647 utterances processed\n",
            "19200/37647 utterances processed\n",
            "19300/37647 utterances processed\n",
            "19400/37647 utterances processed\n",
            "19500/37647 utterances processed\n",
            "19600/37647 utterances processed\n",
            "19700/37647 utterances processed\n",
            "19800/37647 utterances processed\n",
            "19900/37647 utterances processed\n",
            "20000/37647 utterances processed\n",
            "20100/37647 utterances processed\n",
            "20200/37647 utterances processed\n",
            "20300/37647 utterances processed\n",
            "20400/37647 utterances processed\n",
            "20500/37647 utterances processed\n",
            "20600/37647 utterances processed\n",
            "20700/37647 utterances processed\n",
            "20800/37647 utterances processed\n",
            "20900/37647 utterances processed\n",
            "21000/37647 utterances processed\n",
            "21100/37647 utterances processed\n",
            "21200/37647 utterances processed\n",
            "21300/37647 utterances processed\n",
            "21400/37647 utterances processed\n",
            "21500/37647 utterances processed\n",
            "21600/37647 utterances processed\n",
            "21700/37647 utterances processed\n",
            "21800/37647 utterances processed\n",
            "21900/37647 utterances processed\n",
            "22000/37647 utterances processed\n",
            "22100/37647 utterances processed\n",
            "22200/37647 utterances processed\n",
            "22300/37647 utterances processed\n",
            "22400/37647 utterances processed\n",
            "22500/37647 utterances processed\n",
            "22600/37647 utterances processed\n",
            "22700/37647 utterances processed\n",
            "22800/37647 utterances processed\n",
            "22900/37647 utterances processed\n",
            "23000/37647 utterances processed\n",
            "23100/37647 utterances processed\n",
            "23200/37647 utterances processed\n",
            "23300/37647 utterances processed\n",
            "23400/37647 utterances processed\n",
            "23500/37647 utterances processed\n",
            "23600/37647 utterances processed\n",
            "23700/37647 utterances processed\n",
            "23800/37647 utterances processed\n",
            "23900/37647 utterances processed\n",
            "24000/37647 utterances processed\n",
            "24100/37647 utterances processed\n",
            "24200/37647 utterances processed\n",
            "24300/37647 utterances processed\n",
            "24400/37647 utterances processed\n",
            "24500/37647 utterances processed\n",
            "24600/37647 utterances processed\n",
            "24700/37647 utterances processed\n",
            "24800/37647 utterances processed\n",
            "24900/37647 utterances processed\n",
            "25000/37647 utterances processed\n",
            "25100/37647 utterances processed\n",
            "25200/37647 utterances processed\n",
            "25300/37647 utterances processed\n",
            "25400/37647 utterances processed\n",
            "25500/37647 utterances processed\n",
            "25600/37647 utterances processed\n",
            "25700/37647 utterances processed\n",
            "25800/37647 utterances processed\n",
            "25900/37647 utterances processed\n",
            "26000/37647 utterances processed\n",
            "26100/37647 utterances processed\n",
            "26200/37647 utterances processed\n",
            "26300/37647 utterances processed\n",
            "26400/37647 utterances processed\n",
            "26500/37647 utterances processed\n",
            "26600/37647 utterances processed\n",
            "26700/37647 utterances processed\n",
            "26800/37647 utterances processed\n",
            "26900/37647 utterances processed\n",
            "27000/37647 utterances processed\n",
            "27100/37647 utterances processed\n",
            "27200/37647 utterances processed\n",
            "27300/37647 utterances processed\n",
            "27400/37647 utterances processed\n",
            "27500/37647 utterances processed\n",
            "27600/37647 utterances processed\n",
            "27700/37647 utterances processed\n",
            "27800/37647 utterances processed\n",
            "27900/37647 utterances processed\n",
            "28000/37647 utterances processed\n",
            "28100/37647 utterances processed\n",
            "28200/37647 utterances processed\n",
            "28300/37647 utterances processed\n",
            "28400/37647 utterances processed\n",
            "28500/37647 utterances processed\n",
            "28600/37647 utterances processed\n",
            "28700/37647 utterances processed\n",
            "28800/37647 utterances processed\n",
            "28900/37647 utterances processed\n",
            "29000/37647 utterances processed\n",
            "29100/37647 utterances processed\n",
            "29200/37647 utterances processed\n",
            "29300/37647 utterances processed\n",
            "29400/37647 utterances processed\n",
            "29500/37647 utterances processed\n",
            "29600/37647 utterances processed\n",
            "29700/37647 utterances processed\n",
            "29800/37647 utterances processed\n",
            "29900/37647 utterances processed\n",
            "30000/37647 utterances processed\n",
            "30100/37647 utterances processed\n",
            "30200/37647 utterances processed\n",
            "30300/37647 utterances processed\n",
            "30400/37647 utterances processed\n",
            "30500/37647 utterances processed\n",
            "30600/37647 utterances processed\n",
            "30700/37647 utterances processed\n",
            "30800/37647 utterances processed\n",
            "30900/37647 utterances processed\n",
            "31000/37647 utterances processed\n",
            "31100/37647 utterances processed\n",
            "31200/37647 utterances processed\n",
            "31300/37647 utterances processed\n",
            "31400/37647 utterances processed\n",
            "31500/37647 utterances processed\n",
            "31600/37647 utterances processed\n",
            "31700/37647 utterances processed\n",
            "31800/37647 utterances processed\n",
            "31900/37647 utterances processed\n",
            "32000/37647 utterances processed\n",
            "32100/37647 utterances processed\n",
            "32200/37647 utterances processed\n",
            "32300/37647 utterances processed\n",
            "32400/37647 utterances processed\n",
            "32500/37647 utterances processed\n",
            "32600/37647 utterances processed\n",
            "32700/37647 utterances processed\n",
            "32800/37647 utterances processed\n",
            "32900/37647 utterances processed\n",
            "33000/37647 utterances processed\n",
            "33100/37647 utterances processed\n",
            "33200/37647 utterances processed\n",
            "33300/37647 utterances processed\n",
            "33400/37647 utterances processed\n",
            "33500/37647 utterances processed\n",
            "33600/37647 utterances processed\n",
            "33700/37647 utterances processed\n",
            "33800/37647 utterances processed\n",
            "33900/37647 utterances processed\n",
            "34000/37647 utterances processed\n",
            "34100/37647 utterances processed\n",
            "34200/37647 utterances processed\n",
            "34300/37647 utterances processed\n",
            "34400/37647 utterances processed\n",
            "34500/37647 utterances processed\n",
            "34600/37647 utterances processed\n",
            "34700/37647 utterances processed\n",
            "34800/37647 utterances processed\n",
            "34900/37647 utterances processed\n",
            "35000/37647 utterances processed\n",
            "35100/37647 utterances processed\n",
            "35200/37647 utterances processed\n",
            "35300/37647 utterances processed\n",
            "35400/37647 utterances processed\n",
            "35500/37647 utterances processed\n",
            "35600/37647 utterances processed\n",
            "35700/37647 utterances processed\n",
            "35800/37647 utterances processed\n",
            "35900/37647 utterances processed\n",
            "36000/37647 utterances processed\n",
            "36100/37647 utterances processed\n",
            "36200/37647 utterances processed\n",
            "36300/37647 utterances processed\n",
            "36400/37647 utterances processed\n",
            "36500/37647 utterances processed\n",
            "36600/37647 utterances processed\n",
            "36700/37647 utterances processed\n",
            "36800/37647 utterances processed\n",
            "36900/37647 utterances processed\n",
            "37000/37647 utterances processed\n",
            "37100/37647 utterances processed\n",
            "37200/37647 utterances processed\n",
            "37300/37647 utterances processed\n",
            "37400/37647 utterances processed\n",
            "37500/37647 utterances processed\n",
            "37600/37647 utterances processed\n",
            "37647/37647 utterances processed\n"
          ]
        }
      ],
      "source": [
        "from convokit.text_processing import TextParser\n",
        "parser = TextParser(verbosity=100)\n",
        "corpus = parser.transform(corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jc_3ZnHmUrr",
        "outputId": "c1779f12-0661-4a59-9110-83ce33ff6048"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1000/37647 utterances processed\n",
            "2000/37647 utterances processed\n",
            "3000/37647 utterances processed\n",
            "4000/37647 utterances processed\n",
            "5000/37647 utterances processed\n",
            "6000/37647 utterances processed\n",
            "7000/37647 utterances processed\n",
            "8000/37647 utterances processed\n",
            "9000/37647 utterances processed\n",
            "10000/37647 utterances processed\n",
            "11000/37647 utterances processed\n",
            "12000/37647 utterances processed\n",
            "13000/37647 utterances processed\n",
            "14000/37647 utterances processed\n",
            "15000/37647 utterances processed\n",
            "16000/37647 utterances processed\n",
            "17000/37647 utterances processed\n",
            "18000/37647 utterances processed\n",
            "19000/37647 utterances processed\n",
            "20000/37647 utterances processed\n",
            "21000/37647 utterances processed\n",
            "22000/37647 utterances processed\n",
            "23000/37647 utterances processed\n",
            "24000/37647 utterances processed\n",
            "25000/37647 utterances processed\n",
            "26000/37647 utterances processed\n",
            "27000/37647 utterances processed\n",
            "28000/37647 utterances processed\n",
            "29000/37647 utterances processed\n",
            "30000/37647 utterances processed\n",
            "31000/37647 utterances processed\n",
            "32000/37647 utterances processed\n",
            "33000/37647 utterances processed\n",
            "34000/37647 utterances processed\n",
            "35000/37647 utterances processed\n",
            "36000/37647 utterances processed\n",
            "37000/37647 utterances processed\n"
          ]
        }
      ],
      "source": [
        "from convokit import politenessStrategies\n",
        "ps = politenessStrategies.PolitenessStrategies(verbose = 1000)\n",
        "corpus = ps.fit_transform(corpus=corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Cu0obz77BjV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKUovYMnA5Vb",
        "outputId": "b4cd93a2-0409-4bfc-cbc3-64bac9480ce3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "feature_politeness_==Please==                 0.015220\n",
              "feature_politeness_==Please_start==           0.028183\n",
              "feature_politeness_==HASHEDGE==               0.198528\n",
              "feature_politeness_==Indirect_(btw)==         0.000186\n",
              "feature_politeness_==Hedges==                 0.084841\n",
              "feature_politeness_==Factuality==             0.058889\n",
              "feature_politeness_==Deference==              0.014822\n",
              "feature_politeness_==Gratitude==              0.041783\n",
              "feature_politeness_==Apologizing==            0.008739\n",
              "feature_politeness_==1st_person_pl.==         0.068956\n",
              "feature_politeness_==1st_person==             0.251999\n",
              "feature_politeness_==1st_person_start==       0.201291\n",
              "feature_politeness_==2nd_person==             0.233724\n",
              "feature_politeness_==2nd_person_start==       0.053789\n",
              "feature_politeness_==Indirect_(greeting)==    0.009669\n",
              "feature_politeness_==Direct_question==        0.050416\n",
              "feature_politeness_==Direct_start==           0.088188\n",
              "feature_politeness_==HASPOSITIVE==            0.413393\n",
              "feature_politeness_==HASNEGATIVE==            0.345207\n",
              "feature_politeness_==SUBJUNCTIVE==            0.004330\n",
              "feature_politeness_==INDICATIVE==             0.003639\n",
              "dtype: float64"
            ]
          },
          "execution_count": 101,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ps.summarize(corpus=corpus)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "C7ocw_Al4wev",
        "outputId": "c012a609-9e25-4e4f-8c10-4573cb11b0f0"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-cf79f094e14b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(node, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0manytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCountError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExpecting\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0melements\u001b[0m \u001b[0mat\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;36m5.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/f/b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m...\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/f/b/d/e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36m_find\u001b[0;34m(node, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_findall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36m_findall\u001b[0;34m(node, filter_, stop, maxlevel, mincount, maxcount)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_findall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmincount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPreOrderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mresultlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmincount\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresultlen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmincount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/iterators/abstractiter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/iterators/preorderiter.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(children, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchild_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mAbstractIter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abort_at_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-cf79f094e14b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'name'"
          ]
        }
      ],
      "source": [
        "from anytree import Node, find\n",
        "corpus.get_utterance(\"iqp0hc8\")\n",
        "target_node = find(conversations_tree, lambda node: node.name == \"iqp0hc8\")\n",
        "print(target_node.body)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9YXWG1wnGcD",
        "outputId": "ab89344f-cdb9-4ec9-b90c-ef22a2d4a8b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ConvoKitMeta({})"
            ]
          },
          "execution_count": 81,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corpus.get_conversation(\"xsyg0d\").meta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGpu-pED3O--"
      },
      "outputs": [],
      "source": [
        "def calculate_conversation_score(dataset_with_metrics_score, metrics_weights):\n",
        "  i = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYPNS6On_wnn"
      },
      "outputs": [],
      "source": [
        "file_path = base_path + 'train.tsv.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        },
        "id": "yIS9H7VQ4EJu",
        "outputId": "d2041625-4c80-44a7-e87e-cdf927643340"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f94662d4721f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Read the lines and store them in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create a DataFrame from the lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-f94662d4721f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Read the lines and store them in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create a DataFrame from the lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the .tsv.tar.gz file\n",
        "\n",
        "# Open the .tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    # Extract the .tsv.gz file from the .tar.gz archive\n",
        "    tsv_file = tar.getmembers()[0]\n",
        "    file_extension = tsv_file.name.split('.')[-1]\n",
        "\n",
        "    # Check if the file is compressed\n",
        "    if file_extension == 'gz':\n",
        "        # Open the .tsv.gz file\n",
        "        with gzip.open(tar.extractfile(tsv_file), 'rt') as tsv:\n",
        "            # Read the lines and store them in a list\n",
        "            lines = [line.strip() for line in tsv]\n",
        "\n",
        "    else:\n",
        "        # Open the uncompressed .tsv file\n",
        "        with tar.extractfile(tsv_file) as tsv:\n",
        "            # Read the lines and store them in a list\n",
        "            lines = [line.decode().strip() for line in tsv]\n",
        "\n",
        "# Create a DataFrame from the lines\n",
        "df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "# Optionally, you can set the column names based on the first row\n",
        "df.columns = df.iloc[0]\n",
        "df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giecAWqb_nBx"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the .tsv.tar.gz file\n",
        "#file_path = 'path/to/your/file.tsv.tar.gz'\n",
        "\n",
        "# Specify the number of lines to read at a time\n",
        "batch_size = 1000\n",
        "\n",
        "# Open the .tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    # Extract the .tsv.gz file from the .tar.gz archive\n",
        "    tsv_file = tar.getmembers()[0]\n",
        "    file_extension = tsv_file.name.split('.')[-1]\n",
        "\n",
        "    # Check if the file is compressed\n",
        "    if file_extension == 'gz':\n",
        "        # Open the .tsv.gz file\n",
        "        with gzip.open(tar.extractfile(tsv_file), 'rt') as tsv:\n",
        "            # Read the lines in batches\n",
        "            lines = []\n",
        "            for line in tsv:\n",
        "                lines.append(line.strip())\n",
        "                if len(lines) == batch_size:\n",
        "                    # Process the lines and create a DataFrame\n",
        "                    df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "                    # Optionally, set the column names based on the first row\n",
        "                    df.columns = df.iloc[0]\n",
        "                    df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "                    # Do further processing with the DataFrame\n",
        "                    # ...\n",
        "\n",
        "                    # Clear the lines list to free memory\n",
        "                    lines = []\n",
        "\n",
        "            # Process the remaining lines\n",
        "            if lines:\n",
        "                df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df[1:]\n",
        "\n",
        "    else:\n",
        "        # Open the uncompressed .tsv file\n",
        "        with tar.extractfile(tsv_file) as tsv:\n",
        "            # Read the lines in batches\n",
        "            lines = []\n",
        "            for line in tsv:\n",
        "                lines.append(line.decode().strip())\n",
        "                if len(lines) == batch_size:\n",
        "                    # Process the lines and create a DataFrame\n",
        "                    df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "                    # Optionally, set the column names based on the first row\n",
        "                    df.columns = df.iloc[0]\n",
        "                    df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "                    # Do further processing with the DataFrame\n",
        "                    # ...\n",
        "                    print(df.columns)\n",
        "                    # Clear the lines list to free memory\n",
        "                    lines = []\n",
        "\n",
        "            # Process the remaining lines\n",
        "            if lines:\n",
        "                df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df[1:]\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPR2e9wuSLhTeV4kiqj4I2C",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}