{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfsanehHabibi/reddit-conversation-quality/blob/main/Main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_nwsrw4kRxSO",
        "outputId": "4a52d670-9c12-4acc-dad9-3b7ae3b64989"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting anytree\n",
            "  Downloading anytree-2.9.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n",
            "Installing collected packages: anytree\n",
            "Successfully installed anytree-2.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install anytree"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install convokit\n",
        "!python3 -m spacy download en"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j5J5hYGGO0I0",
        "outputId": "0c6cd301-3a11-4845-cc24-13bb36c8b2ef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting convokit\n",
            "  Downloading convokit-3.0.0.tar.gz (183 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/183.2 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.6/183.2 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.2/183.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.7.1)\n",
            "Requirement already satisfied: pandas>=0.23.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.5.3)\n",
            "Collecting msgpack-numpy>=0.4.3.2 (from convokit)\n",
            "  Downloading msgpack_numpy-0.4.8-py2.py3-none-any.whl (6.9 kB)\n",
            "Requirement already satisfied: spacy>=2.3.5 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.5.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.10.1)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.2.2)\n",
            "Requirement already satisfied: nltk>=3.4 in /usr/local/lib/python3.10/dist-packages (from convokit) (3.8.1)\n",
            "Collecting dill>=0.2.9 (from convokit)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from convokit) (1.3.1)\n",
            "Collecting clean-text>=0.6.0 (from convokit)\n",
            "  Downloading clean_text-0.6.0-py3-none-any.whl (11 kB)\n",
            "Collecting unidecode>=1.1.1 (from convokit)\n",
            "  Downloading Unidecode-1.3.6-py3-none-any.whl (235 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m235.9/235.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.64.0 in /usr/local/lib/python3.10/dist-packages (from convokit) (4.65.0)\n",
            "Collecting pymongo>=4.0 (from convokit)\n",
            "  Downloading pymongo-4.4.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (603 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m603.6/603.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml>=5.4.1 in /usr/local/lib/python3.10/dist-packages (from convokit) (6.0.1)\n",
            "Collecting dnspython>=1.16.0 (from convokit)\n",
            "  Downloading dnspython-2.4.1-py3-none-any.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.3/300.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting emoji<2.0.0,>=1.0.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading emoji-1.7.0.tar.gz (175 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.4/175.4 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting ftfy<7.0,>=6.0 (from clean-text>=0.6.0->convokit)\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (4.41.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.4.4)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (3.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.0.0->convokit) (2.8.2)\n",
            "Requirement already satisfied: msgpack>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from msgpack-numpy>=0.4.3.2->convokit) (1.0.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (8.1.6)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.4->convokit) (2022.10.31)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23.4->convokit) (2022.7.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->convokit) (3.2.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (6.3.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (67.7.2)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy>=2.3.5->convokit) (3.3.0)\n",
            "Requirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.10/dist-packages (from ftfy<7.0,>=6.0->clean-text>=0.6.0->convokit) (0.2.6)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy>=2.3.5->convokit) (4.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->convokit) (1.16.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.3.5->convokit) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.3.5->convokit) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy>=2.3.5->convokit) (0.1.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy>=2.3.5->convokit) (2.1.3)\n",
            "Building wheels for collected packages: convokit, emoji\n",
            "  Building wheel for convokit (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for convokit: filename=convokit-3.0.0-py3-none-any.whl size=216708 sha256=e83dfce4c649a740a1dee19240e020edc3b3df6b969d65f2c9af29619086bcd0\n",
            "  Stored in directory: /root/.cache/pip/wheels/c4/89/8c/2677fdb888588b6f93cb6ac86bdfb020f1f1c33e0d5525b231\n",
            "  Building wheel for emoji (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for emoji: filename=emoji-1.7.0-py3-none-any.whl size=171031 sha256=fc3890e81b47186898d72b1da19d8b53ccee2adb3940d09c5ebfdf10f2656932\n",
            "  Stored in directory: /root/.cache/pip/wheels/31/8a/8c/315c9e5d7773f74b33d5ed33f075b49c6eaeb7cedbb86e2cf8\n",
            "Successfully built convokit emoji\n",
            "Installing collected packages: emoji, unidecode, msgpack-numpy, ftfy, dnspython, dill, pymongo, clean-text, convokit\n",
            "Successfully installed clean-text-0.6.0 convokit-3.0.0 dill-0.3.7 dnspython-2.4.1 emoji-1.7.0 ftfy-6.1.1 msgpack-numpy-0.4.8 pymongo-4.4.1 unidecode-1.3.6\n",
            "2023-08-04 06:29:29.351318: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-08-04 06:29:30.764962: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "\u001b[38;5;3m⚠ As of spaCy v3.0, shortcuts like 'en' are deprecated. Please use the\n",
            "full pipeline package name 'en_core_web_sm' instead.\u001b[0m\n",
            "Collecting en-core-web-sm==3.5.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.5.0/en_core_web_sm-3.5.0-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.6.0,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.5.0) (3.5.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.4)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.0.9)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.7)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.0.8)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.8 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.4.7)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.9)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.9.0)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.10.2)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (6.3.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.65.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.22.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.27.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.10.12)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (3.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.7.10)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.2.0,>=8.1.8->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (0.1.0)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (8.1.6)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.6.0,>=3.5.0->en-core-web-sm==3.5.0) (2.1.3)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2nKEu6z62yR",
        "outputId": "d0379f7c-b3b1-46b0-bd53-251aeccc4f16"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "g3cAemLLTz6h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WF_hZIxO64-f"
      },
      "outputs": [],
      "source": [
        "base_path = \"/content/drive/MyDrive/University/RedditData/\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def count_comments_in_file(file_path):\n",
        "    count = 0\n",
        "    with open(file_path, 'r') as json_file:\n",
        "        lines = json_file.readlines()\n",
        "        for line in lines:\n",
        "            data = json.loads(line)\n",
        "            count += len(data.get('comments', []))\n",
        "    return count\n",
        "\n",
        "def total_comments_in_files(file_list_path):\n",
        "    total_comments = 0\n",
        "    with open(file_list_path, 'r') as file_list:\n",
        "        for line in file_list:\n",
        "            print(line)\n",
        "            line = line.strip()\n",
        "            if line:\n",
        "                file_path, _ = line.split(',')\n",
        "                total_comments += count_comments_in_file(f\"{base_path}comments_{file_path}.json\")\n",
        "    return total_comments\n",
        "\n",
        "# Replace 'file_list.txt' with the path to your text file containing the list of file names\n",
        "total_comments = total_comments_in_files(f\"{base_path}timestamps_seed2_num20_period10_date2022-10-1.txt_comments_progress.txt\")\n",
        "print(f'Total number of comments in the files: {total_comments}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-gatXoaOEzjc",
        "outputId": "a2738bfd-f74a-449a-96e4-f157030ed8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1665235800,1\n",
            "\n",
            "1665097800,1\n",
            "\n",
            "1664606400,1\n",
            "\n",
            "1664775600,1\n",
            "\n",
            "1664791200,1\n",
            "\n",
            "1664845200,1\n",
            "\n",
            "1664960400,1\n",
            "\n",
            "1664638200,1\n",
            "\n",
            "1665160800,1\n",
            "\n",
            "1664823600,1\n",
            "\n",
            "1664724000,1\n",
            "\n",
            "1665093000,1\n",
            "\n",
            "1664802000,1\n",
            "\n",
            "1664841000,1\n",
            "\n",
            "1664933400,1\n",
            "\n",
            "1665264000,1\n",
            "\n",
            "1664596200,1\n",
            "\n",
            "1665165600,1\n",
            "\n",
            "1665181200,1\n",
            "\n",
            "1664805000,1\n",
            "\n",
            "Total number of comments in the files: 665973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y8LA9u3SKKna"
      },
      "outputs": [],
      "source": [
        "comments_file = base_path + 'comments_1664638200.json'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conversations_tree = []"
      ],
      "metadata": {
        "id": "eNKkzzWYTwZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4J2-LKSNDV4"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "from anytree import Node, RenderTree\n",
        "\n",
        "# Read the lines from the file\n",
        "with open(comments_file, 'r') as file:\n",
        "    lines = file.readlines()\n",
        "\n",
        "# Create a dictionary to store the comment nodes by their IDs\n",
        "conversations_tree = []\n",
        "flat_comments_list = []\n",
        "# Process each line\n",
        "for line in lines:\n",
        "    comment_nodes = {}\n",
        "    # Parse the JSON object\n",
        "    json_obj = json.loads(line)\n",
        "    # Extract the relevant information from the JSON object\n",
        "    submission_id = json_obj['submission_id']\n",
        "    comments = json_obj['comments']\n",
        "    # Create root node for the submission\n",
        "    ####replace it with the actual body\n",
        "    root = Node(submission_id)\n",
        "    comment_nodes[submission_id] = root\n",
        "    flat_comments_list.append({'id': submission_id, 'body': \"\", 'author':None, 'reply_to':None, 'conversation_id':submission_id})\n",
        "    # Create child nodes for the comments\n",
        "    for comment in comments:\n",
        "        # Check if comment is from a bot and ignore it if it is\n",
        "        if \"I am a bot, and this action was performed automatically\" in comment['body']:\n",
        "            continue\n",
        "\n",
        "        comment_id = comment['id']\n",
        "        author = comment.get('author_fullname', 'unknown')\n",
        "        parent_id = comment['parent_id'].split('_', 1)[-1]\n",
        "        body = comment['body']\n",
        "        # Create a node for the comment with body and ID as attributes\n",
        "        comment_node = Node(comment_id, body=body)\n",
        "        flat_comments_list.append({'id': comment_id, 'body': body, 'author':author, 'reply_to':parent_id, 'conversation_id':submission_id})\n",
        "        if parent_id in comment_nodes:\n",
        "            # Add the comment node as a child to its parent\n",
        "            parent_node = comment_nodes[parent_id]\n",
        "            comment_node.parent = parent_node\n",
        "        else:\n",
        "            # Parent ID is equal to submission ID, make comment a child of the root\n",
        "            comment_node.parent = root\n",
        "            print(\"something is wrong\")\n",
        "\n",
        "        # Store the comment node in the dictionary\n",
        "        comment_nodes[comment_id] = comment_node\n",
        "    # Print the tree structure\n",
        "    # print(RenderTree(root))\n",
        "    conversations_tree.append(root)\n",
        "#print(RenderTree(conversations_tree[2555]))"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FlrAt6TbdzuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flat_comments_list[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dCkbE7L8UGPH",
        "outputId": "59d1f8ba-e7f5-4fd8-f8db-283ab191aef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'id': 'xsyg0d',\n",
              "  'body': '',\n",
              "  'author': None,\n",
              "  'reply_to': None,\n",
              "  'conversation_id': 'xsyg0d'},\n",
              " {'id': 'iqmwd8f',\n",
              "  'body': \"I've been out looking for Ghoulia today, good to know why I couldn't find her.\",\n",
              "  'author': 't2_57iup',\n",
              "  'reply_to': 'xsyg0d',\n",
              "  'conversation_id': 'xsyg0d'},\n",
              " {'id': 'iqn4okm',\n",
              "  'body': 'yeah, fl really got screwed over. was hoping to find my ghouls today but not even a peep, and the workers didn’t even know when they’d be getting stock. i just hope they go online soon',\n",
              "  'author': 't2_mwcj2qdc',\n",
              "  'reply_to': 'xsyg0d',\n",
              "  'conversation_id': 'xsyg0d'}]"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def flatten_tree(node, flattened_tree):\n",
        "    flattened_tree.append(node)\n",
        "    for child in node.children:\n",
        "        flatten_tree(child, flattened_tree)"
      ],
      "metadata": {
        "id": "LSeMoQFZQ5Ze"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "flattened_tree = []\n",
        "flatten_tree(root, flattened_tree)"
      ],
      "metadata": {
        "id": "EWwi-EwdPwJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there is node without body!"
      ],
      "metadata": {
        "id": "jbP4uSHiRw_k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from convokit import Corpus, Utterance, Speaker\n",
        "# Create a Corpus object from the flattened tree.\n",
        "corpus = Corpus(utterances=[\n",
        "        Utterance(id=node['id'], text=node['body'], speaker=Speaker(id = node['author']), reply_to=node['reply_to'], conversation_id=node['conversation_id'])\n",
        "        for node in flat_comments_list\n",
        "])"
      ],
      "metadata": {
        "id": "NwRWOf09RWQr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "corpus = corpus.fit(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        },
        "id": "TEEuPkkmsWXD",
        "outputId": "c4d6035d-67b6-49bd-c138-e3abaa53e4bf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-73-fe0bc8cfc776>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'Corpus' object has no attribute 'fit'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "counter = 0\n",
        "for convo in corpus.iter_conversations():\n",
        "    counter+=1\n",
        "print(counter)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_t26-KJvk3WN",
        "outputId": "0f8803fa-fb8e-4e86-8191-0a0a0d576961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.print_summary_stats()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b__m1fESn2QW",
        "outputId": "bcb5b6bd-2d9b-4f77-de14-cb0966adfd08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Speakers: 20381\n",
            "Number of Utterances: 37647\n",
            "Number of Conversations: 2940\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from convokit.text_processing import TextParser\n",
        "parser = TextParser(verbosity=100)\n",
        "corpus = parser.transform(corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGmGvNjMtr_1",
        "outputId": "07a02ab5-ba26-4d39-95b3-8b80de0e63f4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100/37647 utterances processed\n",
            "200/37647 utterances processed\n",
            "300/37647 utterances processed\n",
            "400/37647 utterances processed\n",
            "500/37647 utterances processed\n",
            "600/37647 utterances processed\n",
            "700/37647 utterances processed\n",
            "800/37647 utterances processed\n",
            "900/37647 utterances processed\n",
            "1000/37647 utterances processed\n",
            "1100/37647 utterances processed\n",
            "1200/37647 utterances processed\n",
            "1300/37647 utterances processed\n",
            "1400/37647 utterances processed\n",
            "1500/37647 utterances processed\n",
            "1600/37647 utterances processed\n",
            "1700/37647 utterances processed\n",
            "1800/37647 utterances processed\n",
            "1900/37647 utterances processed\n",
            "2000/37647 utterances processed\n",
            "2100/37647 utterances processed\n",
            "2200/37647 utterances processed\n",
            "2300/37647 utterances processed\n",
            "2400/37647 utterances processed\n",
            "2500/37647 utterances processed\n",
            "2600/37647 utterances processed\n",
            "2700/37647 utterances processed\n",
            "2800/37647 utterances processed\n",
            "2900/37647 utterances processed\n",
            "3000/37647 utterances processed\n",
            "3100/37647 utterances processed\n",
            "3200/37647 utterances processed\n",
            "3300/37647 utterances processed\n",
            "3400/37647 utterances processed\n",
            "3500/37647 utterances processed\n",
            "3600/37647 utterances processed\n",
            "3700/37647 utterances processed\n",
            "3800/37647 utterances processed\n",
            "3900/37647 utterances processed\n",
            "4000/37647 utterances processed\n",
            "4100/37647 utterances processed\n",
            "4200/37647 utterances processed\n",
            "4300/37647 utterances processed\n",
            "4400/37647 utterances processed\n",
            "4500/37647 utterances processed\n",
            "4600/37647 utterances processed\n",
            "4700/37647 utterances processed\n",
            "4800/37647 utterances processed\n",
            "4900/37647 utterances processed\n",
            "5000/37647 utterances processed\n",
            "5100/37647 utterances processed\n",
            "5200/37647 utterances processed\n",
            "5300/37647 utterances processed\n",
            "5400/37647 utterances processed\n",
            "5500/37647 utterances processed\n",
            "5600/37647 utterances processed\n",
            "5700/37647 utterances processed\n",
            "5800/37647 utterances processed\n",
            "5900/37647 utterances processed\n",
            "6000/37647 utterances processed\n",
            "6100/37647 utterances processed\n",
            "6200/37647 utterances processed\n",
            "6300/37647 utterances processed\n",
            "6400/37647 utterances processed\n",
            "6500/37647 utterances processed\n",
            "6600/37647 utterances processed\n",
            "6700/37647 utterances processed\n",
            "6800/37647 utterances processed\n",
            "6900/37647 utterances processed\n",
            "7000/37647 utterances processed\n",
            "7100/37647 utterances processed\n",
            "7200/37647 utterances processed\n",
            "7300/37647 utterances processed\n",
            "7400/37647 utterances processed\n",
            "7500/37647 utterances processed\n",
            "7600/37647 utterances processed\n",
            "7700/37647 utterances processed\n",
            "7800/37647 utterances processed\n",
            "7900/37647 utterances processed\n",
            "8000/37647 utterances processed\n",
            "8100/37647 utterances processed\n",
            "8200/37647 utterances processed\n",
            "8300/37647 utterances processed\n",
            "8400/37647 utterances processed\n",
            "8500/37647 utterances processed\n",
            "8600/37647 utterances processed\n",
            "8700/37647 utterances processed\n",
            "8800/37647 utterances processed\n",
            "8900/37647 utterances processed\n",
            "9000/37647 utterances processed\n",
            "9100/37647 utterances processed\n",
            "9200/37647 utterances processed\n",
            "9300/37647 utterances processed\n",
            "9400/37647 utterances processed\n",
            "9500/37647 utterances processed\n",
            "9600/37647 utterances processed\n",
            "9700/37647 utterances processed\n",
            "9800/37647 utterances processed\n",
            "9900/37647 utterances processed\n",
            "10000/37647 utterances processed\n",
            "10100/37647 utterances processed\n",
            "10200/37647 utterances processed\n",
            "10300/37647 utterances processed\n",
            "10400/37647 utterances processed\n",
            "10500/37647 utterances processed\n",
            "10600/37647 utterances processed\n",
            "10700/37647 utterances processed\n",
            "10800/37647 utterances processed\n",
            "10900/37647 utterances processed\n",
            "11000/37647 utterances processed\n",
            "11100/37647 utterances processed\n",
            "11200/37647 utterances processed\n",
            "11300/37647 utterances processed\n",
            "11400/37647 utterances processed\n",
            "11500/37647 utterances processed\n",
            "11600/37647 utterances processed\n",
            "11700/37647 utterances processed\n",
            "11800/37647 utterances processed\n",
            "11900/37647 utterances processed\n",
            "12000/37647 utterances processed\n",
            "12100/37647 utterances processed\n",
            "12200/37647 utterances processed\n",
            "12300/37647 utterances processed\n",
            "12400/37647 utterances processed\n",
            "12500/37647 utterances processed\n",
            "12600/37647 utterances processed\n",
            "12700/37647 utterances processed\n",
            "12800/37647 utterances processed\n",
            "12900/37647 utterances processed\n",
            "13000/37647 utterances processed\n",
            "13100/37647 utterances processed\n",
            "13200/37647 utterances processed\n",
            "13300/37647 utterances processed\n",
            "13400/37647 utterances processed\n",
            "13500/37647 utterances processed\n",
            "13600/37647 utterances processed\n",
            "13700/37647 utterances processed\n",
            "13800/37647 utterances processed\n",
            "13900/37647 utterances processed\n",
            "14000/37647 utterances processed\n",
            "14100/37647 utterances processed\n",
            "14200/37647 utterances processed\n",
            "14300/37647 utterances processed\n",
            "14400/37647 utterances processed\n",
            "14500/37647 utterances processed\n",
            "14600/37647 utterances processed\n",
            "14700/37647 utterances processed\n",
            "14800/37647 utterances processed\n",
            "14900/37647 utterances processed\n",
            "15000/37647 utterances processed\n",
            "15100/37647 utterances processed\n",
            "15200/37647 utterances processed\n",
            "15300/37647 utterances processed\n",
            "15400/37647 utterances processed\n",
            "15500/37647 utterances processed\n",
            "15600/37647 utterances processed\n",
            "15700/37647 utterances processed\n",
            "15800/37647 utterances processed\n",
            "15900/37647 utterances processed\n",
            "16000/37647 utterances processed\n",
            "16100/37647 utterances processed\n",
            "16200/37647 utterances processed\n",
            "16300/37647 utterances processed\n",
            "16400/37647 utterances processed\n",
            "16500/37647 utterances processed\n",
            "16600/37647 utterances processed\n",
            "16700/37647 utterances processed\n",
            "16800/37647 utterances processed\n",
            "16900/37647 utterances processed\n",
            "17000/37647 utterances processed\n",
            "17100/37647 utterances processed\n",
            "17200/37647 utterances processed\n",
            "17300/37647 utterances processed\n",
            "17400/37647 utterances processed\n",
            "17500/37647 utterances processed\n",
            "17600/37647 utterances processed\n",
            "17700/37647 utterances processed\n",
            "17800/37647 utterances processed\n",
            "17900/37647 utterances processed\n",
            "18000/37647 utterances processed\n",
            "18100/37647 utterances processed\n",
            "18200/37647 utterances processed\n",
            "18300/37647 utterances processed\n",
            "18400/37647 utterances processed\n",
            "18500/37647 utterances processed\n",
            "18600/37647 utterances processed\n",
            "18700/37647 utterances processed\n",
            "18800/37647 utterances processed\n",
            "18900/37647 utterances processed\n",
            "19000/37647 utterances processed\n",
            "19100/37647 utterances processed\n",
            "19200/37647 utterances processed\n",
            "19300/37647 utterances processed\n",
            "19400/37647 utterances processed\n",
            "19500/37647 utterances processed\n",
            "19600/37647 utterances processed\n",
            "19700/37647 utterances processed\n",
            "19800/37647 utterances processed\n",
            "19900/37647 utterances processed\n",
            "20000/37647 utterances processed\n",
            "20100/37647 utterances processed\n",
            "20200/37647 utterances processed\n",
            "20300/37647 utterances processed\n",
            "20400/37647 utterances processed\n",
            "20500/37647 utterances processed\n",
            "20600/37647 utterances processed\n",
            "20700/37647 utterances processed\n",
            "20800/37647 utterances processed\n",
            "20900/37647 utterances processed\n",
            "21000/37647 utterances processed\n",
            "21100/37647 utterances processed\n",
            "21200/37647 utterances processed\n",
            "21300/37647 utterances processed\n",
            "21400/37647 utterances processed\n",
            "21500/37647 utterances processed\n",
            "21600/37647 utterances processed\n",
            "21700/37647 utterances processed\n",
            "21800/37647 utterances processed\n",
            "21900/37647 utterances processed\n",
            "22000/37647 utterances processed\n",
            "22100/37647 utterances processed\n",
            "22200/37647 utterances processed\n",
            "22300/37647 utterances processed\n",
            "22400/37647 utterances processed\n",
            "22500/37647 utterances processed\n",
            "22600/37647 utterances processed\n",
            "22700/37647 utterances processed\n",
            "22800/37647 utterances processed\n",
            "22900/37647 utterances processed\n",
            "23000/37647 utterances processed\n",
            "23100/37647 utterances processed\n",
            "23200/37647 utterances processed\n",
            "23300/37647 utterances processed\n",
            "23400/37647 utterances processed\n",
            "23500/37647 utterances processed\n",
            "23600/37647 utterances processed\n",
            "23700/37647 utterances processed\n",
            "23800/37647 utterances processed\n",
            "23900/37647 utterances processed\n",
            "24000/37647 utterances processed\n",
            "24100/37647 utterances processed\n",
            "24200/37647 utterances processed\n",
            "24300/37647 utterances processed\n",
            "24400/37647 utterances processed\n",
            "24500/37647 utterances processed\n",
            "24600/37647 utterances processed\n",
            "24700/37647 utterances processed\n",
            "24800/37647 utterances processed\n",
            "24900/37647 utterances processed\n",
            "25000/37647 utterances processed\n",
            "25100/37647 utterances processed\n",
            "25200/37647 utterances processed\n",
            "25300/37647 utterances processed\n",
            "25400/37647 utterances processed\n",
            "25500/37647 utterances processed\n",
            "25600/37647 utterances processed\n",
            "25700/37647 utterances processed\n",
            "25800/37647 utterances processed\n",
            "25900/37647 utterances processed\n",
            "26000/37647 utterances processed\n",
            "26100/37647 utterances processed\n",
            "26200/37647 utterances processed\n",
            "26300/37647 utterances processed\n",
            "26400/37647 utterances processed\n",
            "26500/37647 utterances processed\n",
            "26600/37647 utterances processed\n",
            "26700/37647 utterances processed\n",
            "26800/37647 utterances processed\n",
            "26900/37647 utterances processed\n",
            "27000/37647 utterances processed\n",
            "27100/37647 utterances processed\n",
            "27200/37647 utterances processed\n",
            "27300/37647 utterances processed\n",
            "27400/37647 utterances processed\n",
            "27500/37647 utterances processed\n",
            "27600/37647 utterances processed\n",
            "27700/37647 utterances processed\n",
            "27800/37647 utterances processed\n",
            "27900/37647 utterances processed\n",
            "28000/37647 utterances processed\n",
            "28100/37647 utterances processed\n",
            "28200/37647 utterances processed\n",
            "28300/37647 utterances processed\n",
            "28400/37647 utterances processed\n",
            "28500/37647 utterances processed\n",
            "28600/37647 utterances processed\n",
            "28700/37647 utterances processed\n",
            "28800/37647 utterances processed\n",
            "28900/37647 utterances processed\n",
            "29000/37647 utterances processed\n",
            "29100/37647 utterances processed\n",
            "29200/37647 utterances processed\n",
            "29300/37647 utterances processed\n",
            "29400/37647 utterances processed\n",
            "29500/37647 utterances processed\n",
            "29600/37647 utterances processed\n",
            "29700/37647 utterances processed\n",
            "29800/37647 utterances processed\n",
            "29900/37647 utterances processed\n",
            "30000/37647 utterances processed\n",
            "30100/37647 utterances processed\n",
            "30200/37647 utterances processed\n",
            "30300/37647 utterances processed\n",
            "30400/37647 utterances processed\n",
            "30500/37647 utterances processed\n",
            "30600/37647 utterances processed\n",
            "30700/37647 utterances processed\n",
            "30800/37647 utterances processed\n",
            "30900/37647 utterances processed\n",
            "31000/37647 utterances processed\n",
            "31100/37647 utterances processed\n",
            "31200/37647 utterances processed\n",
            "31300/37647 utterances processed\n",
            "31400/37647 utterances processed\n",
            "31500/37647 utterances processed\n",
            "31600/37647 utterances processed\n",
            "31700/37647 utterances processed\n",
            "31800/37647 utterances processed\n",
            "31900/37647 utterances processed\n",
            "32000/37647 utterances processed\n",
            "32100/37647 utterances processed\n",
            "32200/37647 utterances processed\n",
            "32300/37647 utterances processed\n",
            "32400/37647 utterances processed\n",
            "32500/37647 utterances processed\n",
            "32600/37647 utterances processed\n",
            "32700/37647 utterances processed\n",
            "32800/37647 utterances processed\n",
            "32900/37647 utterances processed\n",
            "33000/37647 utterances processed\n",
            "33100/37647 utterances processed\n",
            "33200/37647 utterances processed\n",
            "33300/37647 utterances processed\n",
            "33400/37647 utterances processed\n",
            "33500/37647 utterances processed\n",
            "33600/37647 utterances processed\n",
            "33700/37647 utterances processed\n",
            "33800/37647 utterances processed\n",
            "33900/37647 utterances processed\n",
            "34000/37647 utterances processed\n",
            "34100/37647 utterances processed\n",
            "34200/37647 utterances processed\n",
            "34300/37647 utterances processed\n",
            "34400/37647 utterances processed\n",
            "34500/37647 utterances processed\n",
            "34600/37647 utterances processed\n",
            "34700/37647 utterances processed\n",
            "34800/37647 utterances processed\n",
            "34900/37647 utterances processed\n",
            "35000/37647 utterances processed\n",
            "35100/37647 utterances processed\n",
            "35200/37647 utterances processed\n",
            "35300/37647 utterances processed\n",
            "35400/37647 utterances processed\n",
            "35500/37647 utterances processed\n",
            "35600/37647 utterances processed\n",
            "35700/37647 utterances processed\n",
            "35800/37647 utterances processed\n",
            "35900/37647 utterances processed\n",
            "36000/37647 utterances processed\n",
            "36100/37647 utterances processed\n",
            "36200/37647 utterances processed\n",
            "36300/37647 utterances processed\n",
            "36400/37647 utterances processed\n",
            "36500/37647 utterances processed\n",
            "36600/37647 utterances processed\n",
            "36700/37647 utterances processed\n",
            "36800/37647 utterances processed\n",
            "36900/37647 utterances processed\n",
            "37000/37647 utterances processed\n",
            "37100/37647 utterances processed\n",
            "37200/37647 utterances processed\n",
            "37300/37647 utterances processed\n",
            "37400/37647 utterances processed\n",
            "37500/37647 utterances processed\n",
            "37600/37647 utterances processed\n",
            "37647/37647 utterances processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from convokit import politenessStrategies\n",
        "ps = politenessStrategies.PolitenessStrategies(verbose = 1000)\n",
        "corpus = ps.fit_transform(corpus=corpus)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Jc_3ZnHmUrr",
        "outputId": "c1779f12-0661-4a59-9110-83ce33ff6048"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1000/37647 utterances processed\n",
            "2000/37647 utterances processed\n",
            "3000/37647 utterances processed\n",
            "4000/37647 utterances processed\n",
            "5000/37647 utterances processed\n",
            "6000/37647 utterances processed\n",
            "7000/37647 utterances processed\n",
            "8000/37647 utterances processed\n",
            "9000/37647 utterances processed\n",
            "10000/37647 utterances processed\n",
            "11000/37647 utterances processed\n",
            "12000/37647 utterances processed\n",
            "13000/37647 utterances processed\n",
            "14000/37647 utterances processed\n",
            "15000/37647 utterances processed\n",
            "16000/37647 utterances processed\n",
            "17000/37647 utterances processed\n",
            "18000/37647 utterances processed\n",
            "19000/37647 utterances processed\n",
            "20000/37647 utterances processed\n",
            "21000/37647 utterances processed\n",
            "22000/37647 utterances processed\n",
            "23000/37647 utterances processed\n",
            "24000/37647 utterances processed\n",
            "25000/37647 utterances processed\n",
            "26000/37647 utterances processed\n",
            "27000/37647 utterances processed\n",
            "28000/37647 utterances processed\n",
            "29000/37647 utterances processed\n",
            "30000/37647 utterances processed\n",
            "31000/37647 utterances processed\n",
            "32000/37647 utterances processed\n",
            "33000/37647 utterances processed\n",
            "34000/37647 utterances processed\n",
            "35000/37647 utterances processed\n",
            "36000/37647 utterances processed\n",
            "37000/37647 utterances processed\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9Cu0obz77BjV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ps.summarize(corpus=corpus)"
      ],
      "metadata": {
        "id": "ZKUovYMnA5Vb",
        "outputId": "b4cd93a2-0409-4bfc-cbc3-64bac9480ce3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "feature_politeness_==Please==                 0.015220\n",
              "feature_politeness_==Please_start==           0.028183\n",
              "feature_politeness_==HASHEDGE==               0.198528\n",
              "feature_politeness_==Indirect_(btw)==         0.000186\n",
              "feature_politeness_==Hedges==                 0.084841\n",
              "feature_politeness_==Factuality==             0.058889\n",
              "feature_politeness_==Deference==              0.014822\n",
              "feature_politeness_==Gratitude==              0.041783\n",
              "feature_politeness_==Apologizing==            0.008739\n",
              "feature_politeness_==1st_person_pl.==         0.068956\n",
              "feature_politeness_==1st_person==             0.251999\n",
              "feature_politeness_==1st_person_start==       0.201291\n",
              "feature_politeness_==2nd_person==             0.233724\n",
              "feature_politeness_==2nd_person_start==       0.053789\n",
              "feature_politeness_==Indirect_(greeting)==    0.009669\n",
              "feature_politeness_==Direct_question==        0.050416\n",
              "feature_politeness_==Direct_start==           0.088188\n",
              "feature_politeness_==HASPOSITIVE==            0.413393\n",
              "feature_politeness_==HASNEGATIVE==            0.345207\n",
              "feature_politeness_==SUBJUNCTIVE==            0.004330\n",
              "feature_politeness_==INDICATIVE==             0.003639\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from anytree import Node, find\n",
        "corpus.get_utterance(\"iqp0hc8\")\n",
        "target_node = find(conversations_tree, lambda node: node.name == \"iqp0hc8\")\n",
        "print(target_node.body)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "C7ocw_Al4wev",
        "outputId": "c012a609-9e25-4e4f-8c10-4573cb11b0f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-100-cf79f094e14b>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(node, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m    163\u001b[0m     \u001b[0manytree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCountError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mExpecting\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0melements\u001b[0m \u001b[0mat\u001b[0m \u001b[0mmaximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbut\u001b[0m \u001b[0mfound\u001b[0m \u001b[0;36m5.\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/f/b'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m...\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/f/b/d/e'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \"\"\"\n\u001b[0;32m--> 165\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36m_find\u001b[0;34m(node, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_find\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m     \u001b[0mitems\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_findall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaxlevel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mitems\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/search.py\u001b[0m in \u001b[0;36m_findall\u001b[0;34m(node, filter_, stop, maxlevel, mincount, maxcount)\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_findall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmincount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 221\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mPreOrderIter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m     \u001b[0mresultlen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmincount\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mresultlen\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mmincount\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/iterators/abstractiter.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/anytree/iterators/preorderiter.py\u001b[0m in \u001b[0;36m_iter\u001b[0;34m(children, filter_, stop, maxlevel)\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mstop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m                 \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mfilter_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mchild_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mAbstractIter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_abort_at_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-100-cf79f094e14b>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(node)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0manytree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcorpus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_utterance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtarget_node\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconversations_tree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"iqp0hc8\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_node\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "corpus.get_conversation(\"xsyg0d\").meta"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b9YXWG1wnGcD",
        "outputId": "ab89344f-cdb9-4ec9-b90c-ef22a2d4a8b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ConvoKitMeta({})"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGpu-pED3O--"
      },
      "outputs": [],
      "source": [
        "def calculate_conversation_score(dataset_with_metrics_score, metrics_weights):\n",
        "  i = 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KYPNS6On_wnn"
      },
      "outputs": [],
      "source": [
        "file_path = base_path + 'train.tsv.tar.gz'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIS9H7VQ4EJu",
        "outputId": "d2041625-4c80-44a7-e87e-cdf927643340",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-f94662d4721f>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Read the lines and store them in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create a DataFrame from the lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-11-f94662d4721f>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtsv_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Read the lines and store them in a list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m             \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtsv\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;31m# Create a DataFrame from the lines\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 700\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    701\u001b[0m         \u001b[0mb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/tarfile.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    687\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    688\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moffset\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposition\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 689\u001b[0;31m                 \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    690\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mReadError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"unexpected end of data\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    299\u001b[0m             \u001b[0;32mimport\u001b[0m \u001b[0merrno\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merrno\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEBADF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"read() on write-only GzipFile object\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/_compression.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mview\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbyte_view\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyte_view\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m             \u001b[0mbyte_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/gzip.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    494\u001b[0m             \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDEFAULT_BUFFER_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 496\u001b[0;31m             \u001b[0muncompress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecompress\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    497\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decompressor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munconsumed_tail\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import tarfile\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the .tsv.tar.gz file\n",
        "\n",
        "# Open the .tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    # Extract the .tsv.gz file from the .tar.gz archive\n",
        "    tsv_file = tar.getmembers()[0]\n",
        "    file_extension = tsv_file.name.split('.')[-1]\n",
        "\n",
        "    # Check if the file is compressed\n",
        "    if file_extension == 'gz':\n",
        "        # Open the .tsv.gz file\n",
        "        with gzip.open(tar.extractfile(tsv_file), 'rt') as tsv:\n",
        "            # Read the lines and store them in a list\n",
        "            lines = [line.strip() for line in tsv]\n",
        "\n",
        "    else:\n",
        "        # Open the uncompressed .tsv file\n",
        "        with tar.extractfile(tsv_file) as tsv:\n",
        "            # Read the lines and store them in a list\n",
        "            lines = [line.decode().strip() for line in tsv]\n",
        "\n",
        "# Create a DataFrame from the lines\n",
        "df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "# Optionally, you can set the column names based on the first row\n",
        "df.columns = df.iloc[0]\n",
        "df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "# Print the DataFrame\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "giecAWqb_nBx"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import gzip\n",
        "import pandas as pd\n",
        "\n",
        "# Specify the path to the .tsv.tar.gz file\n",
        "#file_path = 'path/to/your/file.tsv.tar.gz'\n",
        "\n",
        "# Specify the number of lines to read at a time\n",
        "batch_size = 1000\n",
        "\n",
        "# Open the .tar.gz file\n",
        "with tarfile.open(file_path, 'r:gz') as tar:\n",
        "    # Extract the .tsv.gz file from the .tar.gz archive\n",
        "    tsv_file = tar.getmembers()[0]\n",
        "    file_extension = tsv_file.name.split('.')[-1]\n",
        "\n",
        "    # Check if the file is compressed\n",
        "    if file_extension == 'gz':\n",
        "        # Open the .tsv.gz file\n",
        "        with gzip.open(tar.extractfile(tsv_file), 'rt') as tsv:\n",
        "            # Read the lines in batches\n",
        "            lines = []\n",
        "            for line in tsv:\n",
        "                lines.append(line.strip())\n",
        "                if len(lines) == batch_size:\n",
        "                    # Process the lines and create a DataFrame\n",
        "                    df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "                    # Optionally, set the column names based on the first row\n",
        "                    df.columns = df.iloc[0]\n",
        "                    df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "                    # Do further processing with the DataFrame\n",
        "                    # ...\n",
        "\n",
        "                    # Clear the lines list to free memory\n",
        "                    lines = []\n",
        "\n",
        "            # Process the remaining lines\n",
        "            if lines:\n",
        "                df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df[1:]\n",
        "\n",
        "    else:\n",
        "        # Open the uncompressed .tsv file\n",
        "        with tar.extractfile(tsv_file) as tsv:\n",
        "            # Read the lines in batches\n",
        "            lines = []\n",
        "            for line in tsv:\n",
        "                lines.append(line.decode().strip())\n",
        "                if len(lines) == batch_size:\n",
        "                    # Process the lines and create a DataFrame\n",
        "                    df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "\n",
        "                    # Optionally, set the column names based on the first row\n",
        "                    df.columns = df.iloc[0]\n",
        "                    df = df[1:]  # Remove the first row (column names)\n",
        "\n",
        "                    # Do further processing with the DataFrame\n",
        "                    # ...\n",
        "                    print(df.columns)\n",
        "                    # Clear the lines list to free memory\n",
        "                    lines = []\n",
        "\n",
        "            # Process the remaining lines\n",
        "            if lines:\n",
        "                df = pd.DataFrame([line.split('\\t') for line in lines])\n",
        "                df.columns = df.iloc[0]\n",
        "                df = df[1:]\n",
        "\n",
        "# Print the DataFrame\n",
        "#print(df)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOMJnC2lmUILtev5RmDqrgf",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}