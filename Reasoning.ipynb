{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPX9hdlXCdWyDBT0KZeN1Tj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AfsanehHabibi/reddit-conversation-quality/blob/main/Reasoning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install anytree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Baf9D1PyJyQy",
        "outputId": "28ed6dd0-4aff-442c-dafd-f13ffbaf82a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: anytree in /usr/local/lib/python3.10/dist-packages (2.12.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from anytree) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gH_3qPmYLjG6",
        "outputId": "6a85c4c5-30da-4b4e-b2d6-873e2f5f6375"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = \"/content/drive/MyDrive/University/RedditData/\""
      ],
      "metadata": {
        "id": "X8ggZeKJLnQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "# Reading from a file using Pickle\n",
        "with open(f\"{base_path}conversations_readability.pkl\", 'rb') as file:\n",
        "    conversations = pickle.load(file)\n",
        "\n",
        "# Print the loaded variables\n",
        "print(\"Len conversations:\", len(conversations))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saeRLzg7Lxor",
        "outputId": "29f679d2-7257-4402-e203-37c7095689fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Len conversations: 32990\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u5J56ZGyiP6-"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "def contains_reasoning(text):\n",
        "    doc = nlp(text)\n",
        "\n",
        "    # Check for specific part-of-speech patterns indicating reasoning\n",
        "    reasoning_patterns = [\"because\", \"since\", \"therefore\", \"due to\", \"as a result\", \"consequently\", \"thus\",\n",
        "                          \"for this reason\", \"in conclusion\", \"owing to\", \"on account of\", \"resulting in\",\n",
        "                          \"so\", \"hence\", \"in light of\", \"accordingly\", \"on the grounds that\"]\n",
        "\n",
        "    for token in doc:\n",
        "        if token.text.lower() in reasoning_patterns:\n",
        "            return True\n",
        "\n",
        "    return False"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "VERBOSE = 3000"
      ],
      "metadata": {
        "id": "IMfdi2ltoTe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " def calculate_reasoning_existance_for_conversations():\n",
        "  counter = 0\n",
        "  for id in conversations:\n",
        "    counter += 1\n",
        "    comments = conversations[id]['comments']\n",
        "    for comment in comments:\n",
        "      if not(comment['body'] == '[deleted]' or comment['body'] == '[removed]'):\n",
        "          has_reasoning = contains_reasoning(comment['body'])\n",
        "          comment['has_reasoning'] = has_reasoning\n",
        "    if counter % VERBOSE == 0:\n",
        "      print(counter, \"/\", len(conversations))"
      ],
      "metadata": {
        "id": "angYZPVbSnM2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def write_conversations_with_reasoning():\n",
        "  with open(f\"{base_path}conversations_reasoning.pkl\", 'wb') as file:\n",
        "    pickle.dump(conversations, file)\n",
        "  print(\"Variables written to the file.\")"
      ],
      "metadata": {
        "id": "xOAANFTXTOi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_comments(conversations, num_break_points):\n",
        "  flat_comments_list = []\n",
        "  break_points_index = []\n",
        "  counter = 0\n",
        "  break_length = int(len(conversations)/num_break_points)\n",
        "  print(\"break len \", break_length)\n",
        "  for id in conversations:\n",
        "    if counter % break_length == 0:\n",
        "      break_points_index.append(len(flat_comments_list))\n",
        "    counter += 1\n",
        "    comments = conversations[id]['comments']\n",
        "    for comment in comments:\n",
        "      flat_comments_list.append(comment)\n",
        "\n",
        "  return flat_comments_list, break_points_index"
      ],
      "metadata": {
        "id": "RwKqR4ydx3ko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def write_reasoning_dic(reasoning_dic, file_path):\n",
        "  with open(file_path, 'wb') as file:\n",
        "      pickle.dump(reasoning_dic, file)\n",
        "  print(\"Variables written to the file.\")"
      ],
      "metadata": {
        "id": "pwoEcV_Sx-Gp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "def merge_conversations_with_reasoning(conversations, file_pathes):\n",
        "  reasoning_dic = dict()\n",
        "  for file_path in file_pathes:\n",
        "    with open(file_path, 'rb') as file:\n",
        "      reasoning_part = pickle.load(file)\n",
        "      reasoning_dic.update(reasoning_part)\n",
        "\n",
        "  for id in conversations:\n",
        "    comments = conversations[id]['comments']\n",
        "    for comment in comments:\n",
        "      if not(comment['body'] == '[deleted]' or comment['body'] == '[removed]'):\n",
        "        comment['has_reasoning'] = reasoning_dic[comment['id']]\n",
        "  with open(f\"{base_path}conversations_with_reasoning.pkl\", 'wb') as file:\n",
        "    pickle.dump(conversations, file)\n",
        "  print(\"Variables written to the file.\")"
      ],
      "metadata": {
        "id": "9U4AeeohyBdw"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_reasoning_for_corpus(corpus):\n",
        "  reasoning_dic = dict()\n",
        "  for comment in corpus:\n",
        "      if not(comment['body'] == '[deleted]' or comment['body'] == '[removed]'):\n",
        "          has_reasoning = contains_reasoning(comment['body'])\n",
        "          reasoning_dic[comment['id']] = has_reasoning\n",
        "  return reasoning_dic"
      ],
      "metadata": {
        "id": "YTbNW3XnzU8k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def calculate_reasoning(conversations, num_of_parts, rewrite):\n",
        "  flat_comments, break_points_index = extract_comments(conversations, num_of_parts)\n",
        "  print(\"len \", len(break_points_index))\n",
        "  break_points_index.append(len(flat_comments))\n",
        "  file_pathes = []\n",
        "  for i in range(1, len(break_points_index)):\n",
        "    print(\"range \", break_points_index[i-1], break_points_index[i])\n",
        "    file_path = f\"{base_path}comments_reasoning_{break_points_index[i-1]}_{break_points_index[i]}.pkl\"\n",
        "    file_pathes.append(file_path)\n",
        "    print(\"path \", file_path)\n",
        "    if rewrite or not os.path.exists(file_path):\n",
        "      print(\"do\")\n",
        "      corpus = flat_comments[break_points_index[i-1]:break_points_index[i]]\n",
        "      reasoning_dic = calculate_reasoning_for_corpus(corpus)\n",
        "      write_reasoning_dic(reasoning_dic, file_path)\n",
        "  merge_conversations_with_reasoning(conversations, file_pathes)"
      ],
      "metadata": {
        "id": "q9xvDYzPyFzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "calculate_reasoning(conversations, 10, False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4rB50wkEyJX5",
        "outputId": "94dd23c5-2aaa-42a2-a0f4-4f3342094b2b"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "break len  3299\n",
            "len  10\n",
            "range  0 53506\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_0_53506.pkl\n",
            "range  53506 116967\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_53506_116967.pkl\n",
            "range  116967 178801\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_116967_178801.pkl\n",
            "range  178801 234319\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_178801_234319.pkl\n",
            "range  234319 300115\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_234319_300115.pkl\n",
            "range  300115 357006\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_300115_357006.pkl\n",
            "range  357006 424960\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_357006_424960.pkl\n",
            "range  424960 478226\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_424960_478226.pkl\n",
            "range  478226 533555\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_478226_533555.pkl\n",
            "range  533555 589734\n",
            "path  /content/drive/MyDrive/University/RedditData/comments_reasoning_533555_589734.pkl\n",
            "Variables written to the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "write_conversations_with_reasoning()"
      ],
      "metadata": {
        "id": "r8G3u9eJTYU3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e12cfbbe-222f-4adb-9fcb-48610a6fbf49"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Variables written to the file.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# This model is a `zero-shot-classification` model.\n",
        "# It will classify text, except you are free to choose any label you might imagine\n",
        "classifier = pipeline(model=\"facebook/bart-large-mnli\")\n",
        "classifier(\n",
        "    \"I have a problem with my iphone that needs to be resolved asap!!\",\n",
        "    candidate_labels=[\"urgent\", \"not urgent\", \"phone\", \"tablet\", \"computer\"],\n",
        ")"
      ],
      "metadata": {
        "id": "lRt0l2tUUMeB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "def contains_reasoning_pipeline(text):\n",
        "    # Load the BERT model for text classification\n",
        "    classifier = pipeline('text-classification')\n",
        "\n",
        "    # Define a prompt to classify\n",
        "    prompt = f\"Is the following text reasoning about something? {text}\"\n",
        "\n",
        "    # Use the BERT model to classify the prompt\n",
        "    print(classifier(prompt))\n",
        "\n",
        "    # Check if the predicted label is positive (indicating reasoning)\n",
        "    return False\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gb6mA16VsPKQ",
        "outputId": "fbabb83d-cc75-4dcf-8d84-ce7551d55bc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'label': 'NEGATIVE', 'score': 0.9996144771575928}]\n",
            "The text does not contain reasoning.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "question_answerer = pipeline(task=\"question-answering\")\n",
        "preds = question_answerer(\n",
        "    question=\"What is the reason?\",\n",
        "    context=\"because of everything you said earlier.\",\n",
        ")\n",
        "print(\n",
        "    f\"score: {round(preds['score'], 4)}, start: {preds['start']}, end: {preds['end']}, answer: {preds['answer']}\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5vuQo49uvMm",
        "outputId": "e90f843b-5d48-4acf-d17f-1ee1c7e669a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score: 0.2928, start: 0, end: 38, answer: because of everything you said earlier\n"
          ]
        }
      ]
    }
  ]
}